# IOE-DREAM æ™ºæ…§å›­åŒºä¸€å¡é€šç®¡ç†å¹³å° - éƒ¨ç½²ä¼˜åŒ–æœ€ä½³å®è·µæŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
> **å‘å¸ƒæ—¥æœŸ**: 2025-01-08
> **é€‚ç”¨æ¶æ„**: Spring Boot 3.5.8 + Spring Cloud 2025.0.0 + å¾®æœåŠ¡æ¶æ„
> **æ ¸å¿ƒç›®æ ‡**: æœ€å°åŒ–æœåŠ¡å™¨èµ„æºå ç”¨ï¼Œæœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œç¡®ä¿é«˜å¯ç”¨éƒ¨ç½²

---

## ğŸ“‹ ç›®å½•

1. [éƒ¨ç½²æ¶æ„æ¦‚è¿°](#1-éƒ¨ç½²æ¶æ„æ¦‚è¿°)
2. [ç¯å¢ƒå‡†å¤‡ä¸ä¼˜åŒ–](#2-ç¯å¢ƒå‡†å¤‡ä¸ä¼˜åŒ–)
3. [å¾®æœåŠ¡éƒ¨ç½²ç­–ç•¥](#3-å¾®æœåŠ¡éƒ¨ç½²ç­–ç•¥)
4. [æ€§èƒ½ä¼˜åŒ–é…ç½®](#4-æ€§èƒ½ä¼˜åŒ–é…ç½®)
5. [å®‰å…¨åŠ å›ºé…ç½®](#5-å®‰å…¨åŠ å›ºé…ç½®)
6. [ç›‘æ§å‘Šè­¦ä½“ç³»](#6-ç›‘æ§å‘Šè­¦ä½“ç³»)
7. [è¿ç»´ç®¡ç†æœ€ä½³å®è·µ](#7-è¿ç»´ç®¡ç†æœ€ä½³å®è·µ)
8. [æ•…éšœæ’æŸ¥æŒ‡å—](#8-æ•…éšœæ’æŸ¥æŒ‡å—)
9. [æˆæœ¬ä¼˜åŒ–ç­–ç•¥](#9-æˆæœ¬ä¼˜åŒ–ç­–ç•¥)

---

## 1. éƒ¨ç½²æ¶æ„æ¦‚è¿°

### 1.1 æ•´ä½“æ¶æ„è®¾è®¡

**æ¶æ„åŸåˆ™**:
- âœ… **å¾®æœåŠ¡æ‹†åˆ†**: 9ä¸ªæ ¸å¿ƒå¾®æœåŠ¡ç‹¬ç«‹éƒ¨ç½²
- âœ… **èµ„æºä¼˜åŒ–**: åŸºäºå®é™…è´Ÿè½½åŠ¨æ€åˆ†é…èµ„æº
- âœ… **é«˜å¯ç”¨è®¾è®¡**: å¤šå®ä¾‹éƒ¨ç½² + è´Ÿè½½å‡è¡¡
- âœ… **å®¹å™¨åŒ–éƒ¨ç½²**: Docker + Kubernetesæ ‡å‡†åŒ–

**æ ¸å¿ƒå¾®æœåŠ¡åˆ—è¡¨**:
| æœåŠ¡åç§° | ç«¯å£ | èµ„æºé…ç½® | å®ä¾‹æ•° | è¯´æ˜ |
|---------|------|---------|--------|------|
| ioedream-gateway-service | 8080 | 1C/2G | 2+ | APIç½‘å…³ï¼Œé«˜å¯ç”¨è¦æ±‚ |
| ioedream-common-service | 8088 | 2C/4G | 2+ | å…¬å…±æœåŠ¡ï¼Œä¸šåŠ¡æ ¸å¿ƒ |
| ioedream-device-comm-service | 8087 | 1C/2G | 1+ | è®¾å¤‡é€šè®¯ï¼Œèµ„æºè½»é‡ |
| ioedream-oa-service | 8089 | 2C/4G | 1+ | OAåŠå…¬ï¼Œä¸šåŠ¡æ ¸å¿ƒ |
| ioedream-access-service | 8090 | 1C/2G | 1+ | é—¨ç¦ç®¡ç† |
| ioedream-attendance-service | 8091 | 1C/2G | 1+ | è€ƒå‹¤ç®¡ç† |
| ioedream-video-service | 8092 | 2C/8G | 1+ | è§†é¢‘ç›‘æ§ï¼Œèµ„æºå¯†é›† |
| ioedream-consume-service | 8094 | 2C/4G | 2+ | æ¶ˆè´¹ç®¡ç†ï¼Œé«˜å¹¶å‘ |
| ioedream-visitor-service | 8095 | 1C/2G | 1+ | è®¿å®¢ç®¡ç† |

### 1.2 èµ„æºåˆ†é…ç­–ç•¥

**ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®**:

```yaml
# æ€»èµ„æºé…ç½®ï¼ˆç¤ºä¾‹ï¼‰
cluster:
  total_nodes: 3
  total_cpu: "24 cores"
  total_memory: "64GB"
  total_storage: "500GB SSD"

# æŒ‰æœåŠ¡é‡è¦æ€§åˆ†é…èµ„æºåˆ†é…
resource_allocation:
  # P0çº§æ ¸å¿ƒæœåŠ¡
  gateway_service:
    cpu: "1 core"
    memory: "2GB"
    instances: 2
    priority: "high"

  common_service:
    cpu: "2 cores"
    memory: "4GB"
    instances: 2
    priority: "high"

  # P1çº§ä¸šåŠ¡æœåŠ¡
  consume_service:
    cpu: "2 cores"
    memory: "4GB"
    instances: 2
    priority: "medium"

  video_service:
    cpu: "2 cores"
    memory: "8GB"
    instances: 1
    priority: "medium"

  # P2çº§è¾…åŠ©æœåŠ¡
  other_services:
    cpu: "1 core"
    memory: "2GB"
    instances: 1
    priority: "low"
```

---

## 2. ç¯å¢ƒå‡†å¤‡ä¸ä¼˜åŒ–

### 2.1 æ“ä½œç³»ç»Ÿä¼˜åŒ–

**Linuxç³»ç»Ÿä¼˜åŒ–**:

```bash
#!/bin/bash
# ç³»ç»Ÿå†…æ ¸å‚æ•°ä¼˜åŒ–
cat >> /etc/sysctl.conf << EOF
# ç½‘ç»œä¼˜åŒ–
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_congestion_control = bbr

# æ–‡ä»¶å¥æŸ„ä¼˜åŒ–
fs.file-max = 1000000

# è™šæ‹Ÿå†…å­˜ä¼˜åŒ–
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
EOF

# åº”ç”¨ä¼˜åŒ–
sysctl -p

# ç”¨æˆ·é™åˆ¶ä¼˜åŒ–
cat >> /etc/security/limits.conf << EOF
* soft nofile 65536
* hard nofile 65536
* soft nproc 32768
* hard nproc 32768
EOF
```

**Dockerç¯å¢ƒä¼˜åŒ–**:

```bash
#!/bin/bash
# Dockerå­˜å‚¨é©±åŠ¨ä¼˜åŒ–
cat > /etc/docker/daemon.json << EOF
{
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
  },
  "default-ulimits": {
    "nofile": {
      "Name": "nofile",
      "Hard": 65536,
      "Soft": 65536
    }
  },
  "max-concurrent-downloads": 10,
  "max-concurrent-uploads": 5
}
EOF

systemctl restart docker
```

### 2.2 Kubernetesé›†ç¾¤ä¼˜åŒ–

**MasterèŠ‚ç‚¹ä¼˜åŒ–**:

```yaml
# kubeleté…ç½®ä¼˜åŒ–
cat > /etc/kubernetes/kubelet-config.yaml << EOF
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
maxPods: 200
podPidsLimit: 200
maxOpenFiles: 100000
kubeAPIQPS: 50
kubeAPIBurst: 100
serializeImagePulls: false
imagePullProgressDeadline: "10m"
evictionHard:
  memory.available: "200Mi"
  nodefs.available: "10%"
  nodefs.inodesFree: "5%"
EOF
```

**èµ„æºé…é¢ä¼˜åŒ–**:

```yaml
# namespaceèµ„æºé…é¢
apiVersion: v1
kind: ResourceQuota
metadata:
  name: ioedream-quota
  namespace: ioedream
spec:
  hard:
    requests.cpu: "20"
    requests.memory: 48Gi
    limits.cpu: "24"
    limits.memory: 64Gi
    persistentvolumeclaims: "10"
    services: "20"
    secrets: "20"
    configmaps: "20"
```

---

## 3. å¾®æœåŠ¡éƒ¨ç½²ç­–ç•¥

### 3.1 å®¹å™¨é•œåƒä¼˜åŒ–

**å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–**:

```dockerfile
# Javaåº”ç”¨ä¼˜åŒ–Dockerfile
FROM openjdk:21-jre-slim as builder

# æ„å»ºé˜¶æ®µ
WORKDIR /app
COPY target/*.jar app.jar

# è¿è¡Œé˜¶æ®µ - æœ€å°åŒ–é•œåƒ
FROM eclipse-temurin:21-jre-alpine

# å®‰è£…å¿…è¦å·¥å…·
RUN apk add --no-cache curl jq tzdata && \
    rm -rf /var/cache/apk/*

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1000 appgroup && \
    adduser -D -u 1000 -G appgroup appuser

WORKDIR /app

# åªå¤åˆ¶å¿…è¦æ–‡ä»¶
COPY --from=builder /app/app.jar app.jar
COPY --from=builder /app/BOOT-INF/lib ./lib
COPY --from=builder /app/BOOT-INF/classes ./classes

# è®¾ç½®æƒé™
RUN chown -R appuser:appgroup /app

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:${server.port}/actuator/health || exit 1

# å¯åŠ¨åº”ç”¨
EXPOSE ${server.port}
ENTRYPOINT ["java", "-XX:+UseContainerSupport", "-XX:MaxRAMPercentage=75.0", "-jar", "app.jar"]
```

**é•œåƒå¤§å°ä¼˜åŒ–ç­–ç•¥**:

```bash
# é•œåƒæ¸…ç†è„šæœ¬
#!/bin/bash
docker image prune -f
docker volume prune -f
docker network prune -f

# å¤šæ¶æ„æ„å»º
docker buildx build --platform linux/amd64,linux/arm64 -t ioedream/service:latest .
```

### 3.2 Kuberneteséƒ¨ç½²é…ç½®

**ç½‘å…³æœåŠ¡éƒ¨ç½²**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ioedream-gateway-service
  namespace: ioedream
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: ioedream-gateway-service
  template:
    metadata:
      labels:
        app: ioedream-gateway-service
    spec:
      containers:
      - name: gateway
        image: ioedream/gateway-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: JAVA_OPTS
          value: "-Xms1g -Xmx2g -XX:+UseG1GC"
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: gateway-config
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: ioedream-gateway-service
  namespace: ioedream
spec:
  selector:
    app: ioedream-gateway-service
  ports:
  - name: http
    port: 80
    targetPort: 8080
  type: LoadBalancer
```

**HPAè‡ªåŠ¨æ‰©ç¼©å®¹**:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ioedream-gateway-hpa
  namespace: ioedream
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ioedream-gateway-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 2
        periodSeconds: 15
      selectPolicy: Max
```

---

## 4. æ€§èƒ½ä¼˜åŒ–é…ç½®

### 4.1 JVMè°ƒä¼˜å‚æ•°

**é€šç”¨JVMé…ç½®**:

```bash
# ç”Ÿäº§ç¯å¢ƒJVMå‚æ•°æ¨¡æ¿
JAVA_OPTS="-server \
-Xms${HEAP_SIZE} \
-Xmx${HEAP_SIZE} \
-XX:+UseG1GC \
-XX:MaxGCPauseMillis=200 \
-XX:+UseStringDeduplication \
-XX:+OptimizeStringConcat \
-XX:+UseCompressedOops \
-XX:+UseCompressedClassPointers \
-XX:+UnlockExperimentalVMOptions \
-XX:+UseContainerSupport \
-XX:MaxRAMPercentage=75.0 \
-XX:InitialRAMPercentage=50.0 \
-XX:MinRAMPercentage=25.0 \
-XX:+PrintGCDetails \
-XX:+PrintGCTimeStamps \
-XX:+PrintGCDateStamps \
-XX:+UseGCLogFileRotation \
-XX:NumberOfGCLogFiles=5 \
-XX:GCLogFileSize=10M \
-Xloggc:/var/log/app/gc.log \
-XX:+HeapDumpOnOutOfMemoryError \
-XX:HeapDumpPath=/var/log/app/heapdump.hprof \
-Djava.security.egd=file:/dev/./urandom \
-Dfile.encoding=UTF-8 \
-Duser.timezone=Asia/Shanghai"
```

**ä¸åŒæœåŠ¡ç‰¹å®šè°ƒä¼˜**:

```yaml
# gateway-service - é«˜å¹¶å‘ä¼˜åŒ–
gateway_service_jvm: |
  JAVA_OPTS="-server \
  -Xms2g -Xmx4g \
  -XX:+UseG1GC \
  -XX:MaxGCPauseMillis=150 \
  -XX:+UnlockExperimentalVMOptions \
  -XX:+UseZGC \
  -XX:ConcGCThreads=2 \
  -Dreactor.netty.ioWorkerCount=8 \
  -Dreactor.netty.ioSelectCount=4"

# consume-service - äº‹åŠ¡å¤„ç†ä¼˜åŒ–
consume_service_jvm: |
  JAVA_OPTS="-server \
  -Xms2g -Xmx4g \
  -XX:+UseG1GC \
  -XX:+UseStringDeduplication \
  -Dspring.transaction.default-timeout=30"

# video-service - å†…å­˜å¯†é›†ä¼˜åŒ–
video_service_jvm: |
  JAVA_OPTS="-server \
  -Xms4g -Xmx8g \
  -XX:+UseG1GC \
  -XX:MaxGCPauseMillis=300 \
  -XX:+UseLargePages \
  -XX:LargePageSizeInBytes=2m"
```

### 4.2 æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

**Druidè¿æ¥æ± é…ç½®**:

```yaml
spring:
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      # åŸºç¡€é…ç½®
      initial-size: 10
      min-idle: 10
      max-active: 50
      max-wait: 60000

      # æ€§èƒ½é…ç½®
      query-timeout: 30
      transaction-query-timeout: 30
      queryRetry: 3
      retry-query: true

      # ç›‘æ§é…ç½®
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        reset-enable: false
        login-username: admin
        login-password: ${DRUID_PASSWORD}

      # Webç›‘æ§é…ç½®
      web-stat-filter:
        enabled: true
        url-pattern: /*
        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"

      # æ…¢æŸ¥è¯¢ç›‘æ§
      filter:
        stat:
          enabled: true
          slow-sql-millis: 1000
          log-slow-sql: true
          merge-sql: true
        wall:
          enabled: true
          config:
            multi-statement-allow: false
```

### 4.3 Redisç¼“å­˜ä¼˜åŒ–

**Redisé…ç½®ä¼˜åŒ–**:

```conf
# redis.conf
# å†…å­˜é…ç½®
maxmemory 2gb
maxmemory-policy allkeys-lru
maxmemory-samples 5

# æŒä¹…åŒ–é…ç½®
save 900 1
save 300 10
save 60 10000
rdbcompression yes
rdbchecksum yes

# AOFé…ç½®
appendonly yes
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# ç½‘ç»œé…ç½®
tcp-keepalive 300
timeout 0
tcp-backlog 511

# å®¢æˆ·ç«¯è¿æ¥
maxclients 10000

# æ…¢æŸ¥è¯¢æ—¥å¿—
slowlog-log-slower-than 10000
slowlog-max-len 128

# å†…å­˜ä¼˜åŒ–
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

**Springç¼“å­˜é…ç½®**:

```java
@Configuration
@EnableCaching
public class CacheConfig {

    @Bean
    @Primary
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);

        // ä½¿ç”¨Stringåºåˆ—åŒ–å™¨
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        GenericJackson2JsonRedisSerializer jsonSerializer = new GenericJackson2JsonRedisSerializer();

        // è®¾ç½®keyå’Œvalueçš„åºåˆ—åŒ–è§„åˆ™
        template.setKeySerializer(stringRedisSerializer);
        template.setValueSerializer(jsonSerializer);
        template.setHashKeySerializer(stringRedisSerializer);
        template.setHashValueSerializer(jsonSerializer);

        // è®¾ç½®é»˜è®¤åºåˆ—åŒ–å™¨
        template.setDefaultSerializer(jsonSerializer);

        template.afterPropertiesSet();
        return template;
    }

    @Bean
    public CacheManager cacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
                .entryTtl(Duration.ofMinutes(30))
                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))
                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()))
                .disableCachingNullValues()
                .prefixCacheNameWith("ioedream:");

        return RedisCacheManager.builder(connectionFactory)
                .cacheDefaults(config)
                .transactionAware()
                .build();
    }
}
```

---

## 5. å®‰å…¨åŠ å›ºé…ç½®

### 5.1 å®¹å™¨å®‰å…¨

**å®‰å…¨åŸºç¡€é•œåƒ**:

```dockerfile
# ä½¿ç”¨å®‰å…¨çš„åŸºç¡€é•œåƒ
FROM eclipse-temurin:21-jre-alpine

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# è®¾ç½®æ–‡ä»¶æƒé™
COPY --chown=appuser:appgroup . /app
RUN chmod -R 755 /app && \
    chmod -R 644 /app/*.jar

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# å®‰å…¨æ‰«æ
RUN apk add --no-cache trivy && \
    trivy fs --exit-code 0 --severity HIGH,CRITICAL /app && \
    apk del trivy
```

**Podå®‰å…¨ç­–ç•¥**:

```yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: ioedream-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
```

### 5.2 ç½‘ç»œå®‰å…¨

**NetworkPolicyé…ç½®**:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ioedream-network-policy
  namespace: ioedream
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ioedream
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
  - to:
    - namespaceSelector:
        matchLabels:
          name: database
    ports:
    - protocol: TCP
      port: 3306
    - protocol: TCP
      port: 6379
```

**Ingress TLSé…ç½®**:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ioedream-ingress
  namespace: ioedream
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/ssl-protocols: "TLSv1.2 TLSv1.3"
    nginx.ingress.kubernetes.io/ssl-ciphers: "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.ioedream.com
    secretName: ioedream-tls
  rules:
  - host: api.ioedream.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ioedream-gateway-service
            port:
              number: 80
```

### 5.3 åº”ç”¨å®‰å…¨é…ç½®

**Spring Securityé…ç½®**:

```java
@Configuration
@EnableWebSecurity
@EnableMethodSecurity(prePostEnabled = true)
public class SecurityConfig {

    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
            .csrf(csrf -> csrf.disable())
            .sessionManagement(session -> session.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
            .authorizeHttpRequests(auth -> auth
                .requestMatchers("/actuator/health").permitAll()
                .requestMatchers("/actuator/health/**").permitAll()
                .requestMatchers("/api/v1/auth/**").permitAll()
                .anyRequest().authenticated()
            )
            .oauth2ResourceServer(oauth2 -> oauth2.jwt())
            .headers(headers -> headers
                .contentSecurityPolicy(csp -> csp
                    .policyDirectives("default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'")
                )
                .frameOptions().deny()
                .xssProtection().block(true)
                .httpStrictTransportSecurity().maxAgeInSeconds(31536000).includeSubDomains(true)
            );

        return http.build();
    }

    @Bean
    public WebSecurityCustomizer webSecurityCustomizer() {
        return (web) -> web.ignoring()
                .requestMatchers("/static/**", "/public/**", "/error");
    }
}
```

---

## 6. ç›‘æ§å‘Šè­¦ä½“ç³»

### 6.1 Prometheusé…ç½®

**Prometheusé…ç½®**:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "ioedream_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

  - job_name: 'ioedream-gateway'
    static_configs:
      - targets: ['ioedream-gateway-service:8080']
    metrics_path: '/actuator/prometheus'
    scrape_interval: 10s

  - job_name: 'ioedream-common-service'
    static_configs:
      - targets: ['ioedream-common-service:8088']
    metrics_path: '/actuator/prometheus'
    scrape_interval: 15s
```

**å‘Šè­¦è§„åˆ™é…ç½®**:

```yaml
groups:
- name: ioedream_alerts
  rules:
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service {{ $labels.job }} is down"
      description: "Service {{ $labels.job }} has been down for more than 1 minute."

  - alert: HighCpuUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is above 80% for more than 5 minutes."

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is above 85% for more than 5 minutes."

  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate for {{ $labels.job }}"
      description: "Error rate is above 10% for more than 2 minutes."
```

### 6.2 Grafanaä»ªè¡¨æ¿

**ç³»ç»Ÿæ¦‚è§ˆä»ªè¡¨æ¿**:

```json
{
  "dashboard": {
    "title": "IOE-DREAM ç³»ç»Ÿæ¦‚è§ˆ",
    "panels": [
      {
        "title": "æœåŠ¡çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "up",
            "legendFormat": "{{ job }}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "mappings": [
              {
                "value": "0",
                "text": "DOWN",
                "color": "red"
              },
              {
                "value": "1",
                "text": "UP",
                "color": "green"
              }
            ]
          }
        }
      },
      {
        "title": "è¯·æ±‚ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{ job }} - {{ status }}"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile - {{ job }}"
          }
        ]
      }
    ]
  }
}
```

### 6.3 æ—¥å¿—èšåˆé…ç½®

**ELK Stacké…ç½®**:

```yaml
# elasticsearch.yml
cluster.name: ioedream-logs
node.name: es-node-1
network.host: 0.0.0.0
discovery.type: single-node

# JVMå†…å­˜è®¾ç½®
ES_JAVA_OPTS: "-Xms2g -Xmx2g"

# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "ioedream" {
    json {
      source => "message"
    }

    date {
      match => [ "timestamp", "ISO8601" ]
    }

    if [level] == "ERROR" {
      mutate {
        add_tag => [ "error" ]
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ioedream-logs-%{+YYYY.MM.dd}"
  }
}
```

---

## 7. è¿ç»´ç®¡ç†æœ€ä½³å®è·µ

### 7.1 éƒ¨ç½²æµç¨‹è‡ªåŠ¨åŒ–

**CI/CDæµæ°´çº¿é…ç½®**:

```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - security
  - deploy

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

build:
  stage: build
  script:
    - mvn clean package -DskipTests
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  only:
    - main
    - develop

test:
  stage: test
  script:
    - mvn test
    - mvn jacoco:report
  coverage: '/Total.*?([0-9]{1,3})%/'
  artifacts:
    reports:
      junit:
        - target/surefire-reports/TEST-*.xml
      coverage_report:
        coverage_format: cobertura
        path: target/site/cobertura/coverage.xml

security:
  stage: security
  script:
    - trivy image --exit-code 0 --severity HIGH,CRITICAL $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - dependency-check --project "ioedream" --scan "./target/dependency-check-report.html"

deploy_staging:
  stage: deploy
  script:
    - kubectl set image deployment/ioedream-gateway-service gateway=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA -n ioedream-staging
    - kubectl rollout status deployment/ioedream-gateway-service -n ioedream-staging
  environment:
    name: staging
  only:
    - develop

deploy_production:
  stage: deploy
  script:
    - kubectl set image deployment/ioedream-gateway-service gateway=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA -n ioedream-production
    - kubectl rollout status deployment/ioedream-gateway-service -n ioedream-production
  environment:
    name: production
  when: manual
  only:
    - main
```

### 7.2 å¤‡ä»½ä¸æ¢å¤ç­–ç•¥

**æ•°æ®åº“å¤‡ä»½ç­–ç•¥**:

```bash
#!/bin/bash
# MySQLè‡ªåŠ¨å¤‡ä»½è„šæœ¬

BACKUP_DIR="/backup/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="ioedream"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å…¨é‡å¤‡ä»½
mysqldump -h $DB_HOST -u $DB_USER -p$DB_PASSWORD \
  --single-transaction \
  --routines \
  --triggers \
  --all-databases \
  --flush-logs \
  --master-data=2 \
  | gzip > $BACKUP_DIR/full_backup_$DATE.sql.gz

# ä¿ç•™30å¤©å¤‡ä»½
find $BACKUP_DIR -name "*.sql.gz" -mtime +30 -delete

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
aws s3 cp $BACKUP_DIR/full_backup_$DATE.sql.gz s3://ioedream-backup/mysql/

# è®°å½•å¤‡ä»½æ—¥å¿—
echo "$(date): Full backup completed: full_backup_$DATE.sql.gz" >> /var/log/backup.log
```

**Rediså¤‡ä»½ç­–ç•¥**:

```bash
#!/bin/bash
# Rediså¤‡ä»½è„šæœ¬

REDIS_HOST="redis"
REDIS_PORT="6379"
REDIS_PASSWORD="$REDIS_PASSWORD"
BACKUP_DIR="/backup/redis"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# åˆ›å»ºRediså¤‡ä»½
redis-cli -h $REDIS_HOST -p $REDIS_PORT -a $REDIS_PASSWORD \
  --rdb $BACKUP_DIR/redis_backup_$DATE.rdb

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip $BACKUP_DIR/redis_backup_$DATE.rdb

# ä¿ç•™7å¤©å¤‡ä»½
find $BACKUP_DIR -name "*.rdb.gz" -mtime +7 -delete

echo "$(date): Redis backup completed: redis_backup_$DATE.rdb.gz" >> /var/log/backup.log
```

### 7.3 é…ç½®ç®¡ç†

**ConfigMapé…ç½®**:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ioedream-config
  namespace: ioedream
data:
  application.yml: |
    spring:
      profiles:
        active: production

    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always

      metrics:
        export:
          prometheus:
            enabled: true
        distribution:
          percentiles-histogram:
            http.server.requests: true
          percentiles:
            http.server.requests: 0.5,0.9,0.95,0.99

    logging:
      level:
        net.lab1024: INFO
        org.springframework.security: DEBUG
      pattern:
        console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
        file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
```

**Secreté…ç½®**:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: ioedream-secrets
  namespace: ioedream
type: Opaque
data:
  # Base64ç¼–ç çš„å¯†ç 
  db-password: <base64-encoded-password>
  redis-password: <base64-encoded-password>
  jwt-secret: <base64-encoded-jwt-secret>
```

---

## 8. æ•…éšœæ’æŸ¥æŒ‡å—

### 8.1 å¸¸è§é—®é¢˜è¯Šæ–­

**æœåŠ¡å¯åŠ¨å¤±è´¥**:

```bash
# 1. æ£€æŸ¥PodçŠ¶æ€
kubectl get pods -n ioedream
kubectl describe pod <pod-name> -n ioedream

# 2. æŸ¥çœ‹Podæ—¥å¿—
kubectl logs <pod-name> -n ioedream -f

# 3. æ£€æŸ¥èµ„æºä½¿ç”¨
kubectl top pods -n ioedream
kubectl top nodes

# 4. æ£€æŸ¥äº‹ä»¶
kubectl get events -n ioedream --sort-by='.lastTimestamp'
```

**å†…å­˜æº¢å‡ºæ’æŸ¥**:

```bash
# 1. æŸ¥çœ‹å†…å­˜ä½¿ç”¨
kubectl exec -it <pod-name> -n ioedream -- jstat -gc -t 1

# 2. ç”Ÿæˆå †è½¬å‚¨
kubectl exec -it <pod-name> -n ioedream -- jcmd 1 GC.run_finalization
kubectl exec -it <pod-name> -n ioedream -- jcmd 1 VM.native_memory summary

# 3. åˆ†æå †è½¬å‚¨æ–‡ä»¶
kubectl cp <pod-name>:/var/log/app/heapdump.hprof ./heapdump.hprof
jhat heapdump.hprof
```

**æ•°æ®åº“è¿æ¥é—®é¢˜**:

```bash
# 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
kubectl exec -it <pod-name> -n ioedream -- netstat -an | grep 3306

# 2. æµ‹è¯•æ•°æ®åº“è¿æ¥
kubectl exec -it <pod-name> -n ioedream -- telnet $DB_HOST 3306

# 3. æŸ¥çœ‹è¿æ¥æ± çŠ¶æ€
curl http://<pod-ip>:8080/actuator/druid/stat.json

# 4. æ£€æŸ¥æ…¢æŸ¥è¯¢
mysql -h $DB_HOST -u $DB_USER -p -e "SELECT * FROM mysql.slow_log ORDER BY start_time DESC LIMIT 10;"
```

### 8.2 æ€§èƒ½é—®é¢˜è¯Šæ–­

**å“åº”æ—¶é—´åˆ†æ**:

```bash
# 1. æŸ¥çœ‹åº”ç”¨æ€§èƒ½æŒ‡æ ‡
curl http://<pod-ip>:8080/actuator/metrics/http.server.requests

# 2. JVMæ€§èƒ½åˆ†æ
curl http://<pod-ip>:8080/actuator/metrics/jvm.memory.used
curl http://<pod-ip>:8080/actuator/metrics/jvm.gc.pause

# 3. çº¿ç¨‹åˆ†æ
kubectl exec -it <pod-name> -n ioedream -- jstack 1 > threads.dump

# 4. ç½‘ç»œå»¶è¿Ÿæµ‹è¯•
kubectl exec -it <pod-name> -n ioedream -- ping $DB_HOST -c 10
```

### 8.3 æ•…éšœæ¢å¤é¢„æ¡ˆ

**æœåŠ¡å¿«é€Ÿæ¢å¤**:

```bash
#!/bin/bash
# å¿«é€Ÿæ¢å¤è„šæœ¬

SERVICE_NAME=$1
NAMESPACE="ioedream"

echo "å¼€å§‹æ¢å¤æœåŠ¡: $SERVICE_NAME"

# 1. é‡å¯æœåŠ¡
kubectl rollout restart deployment/$SERVICE_NAME -n $NAMESPACE

# 2. ç­‰å¾…æœåŠ¡å°±ç»ª
kubectl rollout status deployment/$SERVICE_NAME -n $NAMESPACE --timeout=300s

# 3. éªŒè¯æœåŠ¡å¥åº·
kubectl wait --for=condition=ready pod -l app=$SERVICE_NAME -n $NAMESPACE --timeout=300s

# 4. æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get pods -l app=$SERVICE_NAME -n $NAMESPACE

echo "æœåŠ¡ $SERVICE_NAME æ¢å¤å®Œæˆ"
```

---

## 9. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### 9.1 èµ„æºä½¿ç”¨ä¼˜åŒ–

**èµ„æºè¯·æ±‚ä¼˜åŒ–**:

```yaml
# åŸºäºå®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´èµ„æºé…ç½®
apiVersion: v1
kind: LimitRange
metadata:
  name: ioedream-limits
  namespace: ioedream
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "1Gi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    type: Container
  - max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
    type: Container
```

**èŠ‚ç‚¹äº²å’Œæ€§é…ç½®**:

```yaml
# ä¼˜åŒ–èŠ‚ç‚¹è°ƒåº¦
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ioedream-gateway-service
  namespace: ioedream
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values: ["compute"]
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: zone
                operator: In
                values: ["zone-a"]
```

### 9.2 å­˜å‚¨æˆæœ¬ä¼˜åŒ–

**å­˜å‚¨ç±»é…ç½®**:

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ioedream-ssd
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  fsType: ext4
reclaimPolicy: Retain
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
```

**PVç”Ÿå‘½å‘¨æœŸç®¡ç†**:

```yaml
# è‡ªåŠ¨æ¸…ç†è¿‡æœŸPV
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-expired-pv
  namespace: ioedream
spec:
  schedule: "0 2 * * 0"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: cleanup
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              kubectl get pv -o json | jq '.items[] | select(.status.phase == "Released") | .metadata.name' | xargs -I {} kubectl delete pv {}
          restartPolicy: OnFailure
```

### 9.3 ç½‘ç»œæˆæœ¬ä¼˜åŒ–

**Ingressæ§åˆ¶å™¨ä¼˜åŒ–**:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ioedream-gateway-service
  namespace: ioedream
  annotations:
    # ä½¿ç”¨å†…éƒ¨è´Ÿè½½å‡è¡¡å™¨èŠ‚çœæˆæœ¬
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
    # å¯ç”¨è·¨å¯ç”¨åŒºè´Ÿè½½å‡è¡¡
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    # å¯ç”¨è¿æ¥æ’ç©º
    service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled: "true"
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  loadBalancerSourceRanges:
  - 10.0.0.0/8
  - 172.16.0.0/12
  - 192.168.0.0/16
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ç›‘æ§

### å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰

| æŒ‡æ ‡ç±»åˆ« | æŒ‡æ ‡åç§° | ç›®æ ‡å€¼ | å‘Šè­¦é˜ˆå€¼ |
|---------|---------|--------|----------|
| **ç³»ç»Ÿæ€§èƒ½** | CPUä½¿ç”¨ç‡ | < 70% | > 85% |
| | å†…å­˜ä½¿ç”¨ç‡ | < 80% | > 90% |
| | ç£ç›˜ä½¿ç”¨ç‡ | < 70% | > 85% |
| **åº”ç”¨æ€§èƒ½** | å“åº”æ—¶é—´(P95) | < 200ms | > 500ms |
| | ååé‡(QPS) | > 1000 | < 500 |
| | é”™è¯¯ç‡ | < 1% | > 5% |
| **æ•°æ®åº“æ€§èƒ½** | è¿æ¥æ•°ä½¿ç”¨ç‡ | < 80% | > 90% |
| | æŸ¥è¯¢å“åº”æ—¶é—´ | < 100ms | > 300ms |
| | æ…¢æŸ¥è¯¢æ¯”ä¾‹ | < 1% | > 5% |
| **ç¼“å­˜æ€§èƒ½** | ç¼“å­˜å‘½ä¸­ç‡ | > 90% | < 80% |
| | ç¼“å­˜å“åº”æ—¶é—´ | < 10ms | > 50ms |

### æˆæœ¬æ•ˆç›Šåˆ†æ

```yaml
# èµ„æºä½¿ç”¨æ•ˆç‡æŒ‡æ ‡
resource_efficiency:
  cpu_utilization:
    target: "70-80%"
    current: "65%"
    action: "ä¼˜åŒ–è°ƒåº¦ç­–ç•¥ï¼Œæé«˜CPUåˆ©ç”¨ç‡"

  memory_utilization:
    target: "75-85%"
    current: "60%"
    action: "è°ƒæ•´å†…å­˜é…ç½®ï¼Œé¿å…è¿‡åº¦åˆ†é…"

  storage_efficiency:
    target: ">80%"
    current: "70%"
    action: "æ¸…ç†æ— ç”¨æ•°æ®ï¼Œä¼˜åŒ–å­˜å‚¨åˆ†é…"

# æˆæœ¬èŠ‚çº¦ç›®æ ‡
cost_optimization:
  monthly_target: "é™ä½15%"
  current_saving: "8%"
  strategies:
    - "ä½¿ç”¨Spotå®ä¾‹å¤„ç†éå…³é”®è´Ÿè½½"
    - "å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹å‡å°‘ç©ºé—²èµ„æº"
    - "ä¼˜åŒ–é•œåƒå¤§å°å‡å°‘å­˜å‚¨æˆæœ¬"
    - "ä½¿ç”¨é¢„ä»˜è´¹å®ä¾‹é™ä½å•ä»·"
```

---

## ğŸ¯ æ€»ç»“ä¸æœ€ä½³å®è·µå»ºè®®

### æ ¸å¿ƒä¼˜åŒ–åŸåˆ™

1. **èµ„æºåˆç†åˆ†é…**
   - åŸºäºå®é™…è´Ÿè½½åŠ¨æ€è°ƒæ•´èµ„æºé…ç½®
   - ä½¿ç”¨HPAå®ç°è‡ªåŠ¨æ‰©ç¼©å®¹
   - é¿å…èµ„æºè¿‡åº¦åˆ†é…

2. **æ€§èƒ½æŒç»­ä¼˜åŒ–**
   - å®šæœŸç›‘æ§å’Œåˆ†ææ€§èƒ½æŒ‡æ ‡
   - ä½¿ç”¨JVMè°ƒä¼˜å‚æ•°ä¼˜åŒ–Javaåº”ç”¨
   - ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç´¢å¼•

3. **å®‰å…¨ç¬¬ä¸€åŸåˆ™**
   - å®æ–½å¤šå±‚æ¬¡å®‰å…¨é˜²æŠ¤
   - å®šæœŸå®‰å…¨æ‰«æå’Œæ¼æ´ä¿®å¤
   - éµå¾ªæœ€å°æƒé™åŸåˆ™

4. **è¿ç»´è‡ªåŠ¨åŒ–**
   - å®ç°CI/CDè‡ªåŠ¨åŒ–éƒ¨ç½²
   - å»ºç«‹å®Œå–„çš„ç›‘æ§å‘Šè­¦ä½“ç³»
   - åˆ¶å®šè¯¦ç»†çš„æ•…éšœæ¢å¤é¢„æ¡ˆ

### æŒç»­æ”¹è¿›è®¡åˆ’

- **æœˆåº¦å›é¡¾**: åˆ†ææ€§èƒ½æŒ‡æ ‡ï¼Œè¯†åˆ«ä¼˜åŒ–æœºä¼š
- **å­£åº¦è¯„ä¼°**: è¯„ä¼°æ¶æ„åˆç†æ€§ï¼Œè§„åˆ’æŠ€æœ¯å‡çº§
- **å¹´åº¦ä¼˜åŒ–**: å…¨é¢ç³»ç»Ÿä¼˜åŒ–ï¼ŒæŠ€æœ¯æ ˆå‡çº§

---

**ğŸ“ æŠ€æœ¯æ”¯æŒ**:
- **æ¶æ„å›¢é˜Ÿ**: è´Ÿè´£æ¶æ„è®¾è®¡å’Œä¼˜åŒ–æŒ‡å¯¼
- **è¿ç»´å›¢é˜Ÿ**: è´Ÿè´£ç³»ç»Ÿéƒ¨ç½²å’Œæ—¥å¸¸ç»´æŠ¤
- **å®‰å…¨å›¢é˜Ÿ**: è´Ÿè´£å®‰å…¨åŠ å›ºå’Œåˆè§„æ£€æŸ¥

**ğŸ”„ ç‰ˆæœ¬æ›´æ–°**:
- æœ¬æ–‡æ¡£å°†æ ¹æ®æŠ€æœ¯å‘å±•å’Œå®è·µç»éªŒæŒç»­æ›´æ–°
- å»ºè®®æ¯å­£åº¦è¿›è¡Œä¸€æ¬¡å…¨é¢å®¡æŸ¥å’Œä¼˜åŒ–

---

*æœ¬æ–‡æ¡£ç”±IOE-DREAMæ¶æ„å§”å‘˜ä¼šåˆ¶å®šï¼Œä¸ºæ™ºæ…§å›­åŒºä¸€å¡é€šç®¡ç†å¹³å°çš„ç”Ÿäº§éƒ¨ç½²æä¾›å…¨é¢çš„æœ€ä½³å®è·µæŒ‡å¯¼ã€‚*