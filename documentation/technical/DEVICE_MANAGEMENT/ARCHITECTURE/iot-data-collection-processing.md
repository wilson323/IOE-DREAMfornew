# ğŸ“Š IOTè®¾å¤‡æ•°æ®é‡‡é›†å’Œå¤„ç†æ¶æ„è®¾è®¡

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-16
**æœ€åæ›´æ–°**: 2025-11-16
**ç»´æŠ¤è€…**: SmartAdmin Team**
**å‚è€ƒæ ‡å‡†**: IOTæ•°æ®å¤„ç†æ ‡å‡†ã€æµå¤„ç†æ¶æ„æœ€ä½³å®è·µ

---

## ğŸ“‹ æ¦‚è¿°

IOTè®¾å¤‡æ•°æ®é‡‡é›†å’Œå¤„ç†æ˜¯ä¼ä¸šçº§IOTå¹³å°çš„æ ¸å¿ƒæ•°æ®å¤„ç†å±‚ï¼Œè´Ÿè´£æµ·é‡è®¾å¤‡æ•°æ®çš„å®æ—¶é‡‡é›†ã€ä¼ è¾“ã€å¤„ç†ã€å­˜å‚¨å’Œåˆ†æã€‚æœ¬æ–‡æ¡£åŸºäºIOE-DREAMé¡¹ç›®éœ€æ±‚ï¼Œè®¾è®¡äº†ä¸€å¥—é«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„æ•°æ®å¤„ç†æ¶æ„ï¼Œæ”¯æŒå®æ—¶æµå¤„ç†ã€æ‰¹é‡åˆ†æã€æœºå™¨å­¦ä¹ å’Œæ•°æ®å¯è§†åŒ–ç­‰åŠŸèƒ½ã€‚

### ğŸ¯ è®¾è®¡ç›®æ ‡

- **é«˜ååé‡**: æ”¯æŒæ¯ç§’ç™¾ä¸‡çº§æ•°æ®ç‚¹å¤„ç†
- **ä½å»¶è¿Ÿ**: å®æ—¶æ•°æ®å¤„ç†å»¶è¿Ÿ<100ms
- **é«˜å¯é æ€§**: æ•°æ®å¤„ç†å¯é æ€§â‰¥99.99%
- **å¯æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³æ‰©å±•å’Œå¼¹æ€§ä¼¸ç¼©
- **å¤šåè®®æ”¯æŒ**: æ”¯æŒå¤šç§IOTåè®®å’Œæ•°æ®æ ¼å¼
- **æ™ºèƒ½åŒ–**: é›†æˆæœºå™¨å­¦ä¹ å’ŒAIåˆ†æèƒ½åŠ›

---

## ğŸ—ï¸ æ•°æ®å¤„ç†æ¶æ„æ¦‚è§ˆ

### ğŸ“ æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "æ•°æ®é‡‡é›†å±‚"
        A1[MQTTè®¾å¤‡]
        A2[HTTPè®¾å¤‡]
        A3[TCP/UDPè®¾å¤‡]
        A4[WebSocketè®¾å¤‡]
        A5[CoAPè®¾å¤‡]
        A6[ç¬¬ä¸‰æ–¹ç³»ç»Ÿ]
    end

    subgraph "åè®®ç½‘å…³å±‚"
        B1[MQTTç½‘å…³<br/>EMQX]
        B2[HTTPç½‘å…³<br/>Spring Gateway]
        B3[TCPç½‘å…³<br/>Netty]
        B4[WebSocketç½‘å…³<br/>SockJS]
        B5[æ•°æ®é¢„å¤„ç†<br/>Validation & Filter]
    end

    subgraph "æ¶ˆæ¯ä¸­é—´ä»¶å±‚"
        C1[Apache Kafka<br/>ä¸»æ•°æ®æµ]
        C2[RabbitMQ<br/>å‘½ä»¤æ¶ˆæ¯]
        C3[Redis Pub/Sub<br/>å®æ—¶é€šçŸ¥]
        C4[Pulsar<br/>å¤šç§Ÿæˆ·éš”ç¦»]
    end

    subgraph "æµå¤„ç†å±‚"
        D1[Flinkä½œä¸š<br/>å®æ—¶è®¡ç®—]
        D2[Spark Streaming<br/>æµå¼åˆ†æ]
        D3[Storm<br/>å¤æ‚äº‹ä»¶å¤„ç†]
        D4[è§„åˆ™å¼•æ“<br/>ä¸šåŠ¡è§„åˆ™]
    end

    subgraph "æ•°æ®å¤„ç†å±‚"
        E1[æ•°æ®æ¸…æ´—<br/>Clean & Normalize]
        E2[æ•°æ®è½¬æ¢<br/>Transform & Enrich]
        E3[æ•°æ®èšåˆ<br/>Aggregate & Summarize]
        E4[å¼‚å¸¸æ£€æµ‹<br/>Anomaly Detection]
        E5[å®æ—¶å‘Šè­¦<br/>Alert Engine]
    end

    subgraph "å­˜å‚¨å±‚"
        F1[InfluxDB<br/>æ—¶åºæ•°æ®]
        F2[ClickHouse<br/>åˆ†ææ•°æ®]
        F3[MongoDB<br/>æ–‡æ¡£æ•°æ®]
        F4[MySQL<br/>å…³ç³»æ•°æ®]
        F5[ElasticSearch<br/>æœç´¢æ•°æ®]
        F6[HDFS<br/>å¤§æ•°æ®å­˜å‚¨]
    end

    subgraph "åˆ†æå±‚"
        G1[å®æ—¶åˆ†æ<br/>Real-time Analytics]
        G2[æ‰¹é‡åˆ†æ<br/>Batch Analytics]
        G3[æœºå™¨å­¦ä¹ <br/>ML Pipeline]
        G4[æ•°æ®æŒ–æ˜<br/>Data Mining]
    end

    subgraph "æœåŠ¡å±‚"
        H1[æ•°æ®API<br/>GraphQL/REST]
        H2[å®æ—¶ä»ªè¡¨æ¿<br/>Dashboard]
        H3[æŠ¥è¡¨æœåŠ¡<br/>Reporting]
        H4[é€šçŸ¥æœåŠ¡<br/>Notification]
    end

    A1 --> B1
    A2 --> B2
    A3 --> B3
    A4 --> B4
    A5 --> B1
    A6 --> B2

    B1 --> C1
    B2 --> C1
    B3 --> C1
    B4 --> C1
    B5 --> C1

    C1 --> D1
    C1 --> D2
    C1 --> D3
    C2 --> D4

    D1 --> E1
    D2 --> E2
    D3 --> E3
    D4 --> E4
    E5 --> C3

    E1 --> F1
    E2 --> F2
    E3 --> F3
    E4 --> F4
    E5 --> F5

    F1 --> G1
    F2 --> G2
    F3 --> G3
    F4 --> G4

    G1 --> H1
    G2 --> H2
    G3 --> H3
    G4 --> H4
```

### ğŸ”§ æ•°æ®æµå¤„ç†æ¶æ„

```mermaid
sequenceDiagram
    participant Device as IOTè®¾å¤‡
    participant Gateway as åè®®ç½‘å…³
    participant Kafka as æ¶ˆæ¯é˜Ÿåˆ—
    participant Flink as æµå¤„ç†å¼•æ“
    participant Storage as å­˜å‚¨å±‚
    participant Analytics as åˆ†æå¼•æ“
    participant API as æ•°æ®æœåŠ¡

    Device->>Gateway: å‘é€è®¾å¤‡æ•°æ®
    Gateway->>Gateway: åè®®è§£æå’ŒéªŒè¯
    Gateway->>Kafka: å‘å¸ƒåˆ°åŸå§‹æ•°æ®Topic

    par å®æ—¶å¤„ç†æµ
        Kafka->>Flink: å®æ—¶æ•°æ®æ¶ˆè´¹
        Flink->>Flink: æ•°æ®æ¸…æ´—å’Œè½¬æ¢
        Flink->>Flink: å®æ—¶èšåˆè®¡ç®—
        Flink->>Storage: å†™å…¥æ—¶åºæ•°æ®åº“
        Flink->>Analytics: è§¦å‘å®æ—¶åˆ†æ
    and å‘Šè­¦å¤„ç†æµ
        Kafka->>Flink: å‘Šè­¦è§„åˆ™æ£€æŸ¥
        Flink->>API: å‘é€å®æ—¶å‘Šè­¦
    and æ‰¹é‡å¤„ç†æµ
        Kafka->>Storage: åŸå§‹æ•°æ®å½’æ¡£
        Storage->>Analytics: æ‰¹é‡æ•°æ®åˆ†æ
    end

    API->>API: æ•°æ®æŸ¥è¯¢å’Œå¤„ç†
    API->>Storage: è¯»å–å­˜å‚¨æ•°æ®
    API-->>Device: è¿”å›å¤„ç†ç»“æœ
```

---

## ğŸ”Œ æ•°æ®é‡‡é›†å±‚è®¾è®¡

### ğŸ“¡ å¤šåè®®æ•°æ®æ¥å…¥

#### 1. MQTTæ•°æ®é‡‡é›†

```java
@Component
@Slf4j
public class MqttDataCollector {

    @Resource
    private MqttClientPool mqttClientPool;

    @Resource
    private DataPublisher dataPublisher;

    @Resource
    private MessageValidator messageValidator;

    /**
     * MQTTæ¶ˆæ¯å¤„ç†å™¨
     */
    @Component
    public static class MqttMessageHandler implements MqttCallback {

        @Resource
        private DataProcessor dataProcessor;

        @Override
        public void messageArrived(String topic, MqttMessage message) {
            try {
                // 1. è§£æTopicè·å–è®¾å¤‡ä¿¡æ¯
                TopicInfo topicInfo = parseTopic(topic);

                // 2. éªŒè¯æ¶ˆæ¯æ ¼å¼
                if (!messageValidator.validate(message)) {
                    log.warn("MQTTæ¶ˆæ¯éªŒè¯å¤±è´¥: topic={}", topic);
                    return;
                }

                // 3. æ„å»ºè®¾å¤‡æ•°æ®å¯¹è±¡
                DeviceData deviceData = DeviceData.builder()
                        .deviceId(topicInfo.getDeviceId())
                        .timestamp(Instant.now())
                        .protocol("MQTT")
                        .topic(topic)
                        .payload(message.getPayload())
                        .qos(message.getQos())
                        .retained(message.isRetained())
                        .build();

                // 4. å¤„ç†è®¾å¤‡æ•°æ®
                dataProcessor.process(deviceData);

            } catch (Exception e) {
                log.error("å¤„ç†MQTTæ¶ˆæ¯å¤±è´¥: topic={}", topic, e);
            }
        }

        private TopicInfo parseTopic(String topic) {
            // è§£æTopicæ ¼å¼: device/{deviceId}/data/{dataType}
            String[] parts = topic.split("/");
            return TopicInfo.builder()
                    .deviceType(parts[0])
                    .deviceId(parts[1])
                    .messageType(parts[2])
                    .dataType(parts.length > 3 ? parts[3] : "default")
                    .build();
        }
    }

    /**
     * æ‰¹é‡MQTTæ•°æ®å¤„ç†
     */
    @KafkaListener(topics = "mqtt.raw.data", groupId = "mqtt-data-processor")
    public void processBatchMqttData(List<MqttRawData> rawDataList) {
        try {
            List<DeviceData> deviceDataList = rawDataList.stream()
                    .map(this::convertToDeviceData)
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());

            if (!deviceDataList.isEmpty()) {
                // æ‰¹é‡å‘å¸ƒåˆ°æ•°æ®æµ
                dataPublisher.publishBatch(deviceDataList);
            }

        } catch (Exception e) {
            log.error("æ‰¹é‡å¤„ç†MQTTæ•°æ®å¤±è´¥", e);
        }
    }
}
```

#### 2. HTTPæ•°æ®é‡‡é›†

```java
@RestController
@RequestMapping("/api/v1/data")
@Slf4j
public class HttpDataCollector {

    @Resource
    private DataProcessor dataProcessor;

    @Resource
    private RateLimiter rateLimiter;

    /**
     * æ¥æ”¶è®¾å¤‡æ•°æ®ä¸ŠæŠ¥
     */
    @PostMapping("/upload")
    @PreAuthorize("hasRole('DEVICE_DATA_UPLOAD')")
    public ResponseDTO<String> uploadDeviceData(
            @RequestHeader("X-Device-ID") String deviceId,
            @RequestHeader("X-Device-Token") String deviceToken,
            @Valid @RequestBody DeviceDataUploadRequest request) {

        try {
            // 1. éªŒè¯è®¾å¤‡Token
            if (!validateDeviceToken(deviceId, deviceToken)) {
                return ResponseDTO.error(UserErrorCode.UNAUTHORIZED, "è®¾å¤‡TokenéªŒè¯å¤±è´¥");
            }

            // 2. é™æµæ£€æŸ¥
            if (!rateLimiter.tryAcquire(deviceId)) {
                return ResponseDTO.error(UserErrorCode.RATE_LIMIT_EXCEEDED, "è®¾å¤‡ä¸ŠæŠ¥é¢‘ç‡è¶…é™");
            }

            // 3. æ„å»ºè®¾å¤‡æ•°æ®å¯¹è±¡
            DeviceData deviceData = DeviceData.builder()
                    .deviceId(deviceId)
                    .timestamp(Instant.now())
                    .protocol("HTTP")
                    .dataType(request.getDataType())
                    .payload(request.getPayload())
                    .metadata(request.getMetadata())
                    .build();

            // 4. å¼‚æ­¥å¤„ç†æ•°æ®
            CompletableFuture.runAsync(() -> dataProcessor.process(deviceData));

            return ResponseDTO.ok("æ•°æ®ä¸ŠæŠ¥æˆåŠŸ");

        } catch (Exception e) {
            log.error("å¤„ç†è®¾å¤‡æ•°æ®ä¸ŠæŠ¥å¤±è´¥: deviceId={}", deviceId, e);
            return ResponseDTO.error(UserErrorCode.SYSTEM_ERROR, "æ•°æ®å¤„ç†å¤±è´¥");
        }
    }

    /**
     * æ‰¹é‡æ•°æ®ä¸ŠæŠ¥
     */
    @PostMapping("/batch-upload")
    @PreAuthorize("hasRole('DEVICE_DATA_UPLOAD')")
    public ResponseDTO<String> batchUploadDeviceData(
            @RequestHeader("X-Device-ID") String deviceId,
            @RequestHeader("X-Device-Token") String deviceToken,
            @Valid @RequestBody BatchDeviceDataUploadRequest request) {

        try {
            // 1. éªŒè¯è®¾å¤‡Tokenå’Œé™æµ
            if (!validateDeviceToken(deviceId, deviceToken)) {
                return ResponseDTO.error(UserErrorCode.UNAUTHORIZED, "è®¾å¤‡TokenéªŒè¯å¤±è´¥");
            }

            if (!rateLimiter.tryAcquire(deviceId, request.getDataList().size())) {
                return ResponseDTO.error(UserErrorCode.RATE_LIMIT_EXCEEDED, "æ‰¹é‡ä¸ŠæŠ¥é¢‘ç‡è¶…é™");
            }

            // 2. æ‰¹é‡è½¬æ¢æ•°æ®
            List<DeviceData> deviceDataList = request.getDataList().stream()
                    .map(data -> DeviceData.builder()
                            .deviceId(deviceId)
                            .timestamp(Instant.ofEpochMilli(data.getTimestamp()))
                            .protocol("HTTP")
                            .dataType(data.getDataType())
                            .payload(data.getPayload())
                            .metadata(data.getMetadata())
                            .build())
                    .collect(Collectors.toList());

            // 3. æ‰¹é‡å¤„ç†æ•°æ®
            dataProcessor.processBatch(deviceDataList);

            return ResponseDTO.ok(String.format("æ‰¹é‡æ•°æ®ä¸ŠæŠ¥æˆåŠŸï¼Œå…±%dæ¡", deviceDataList.size()));

        } catch (Exception e) {
            log.error("å¤„ç†æ‰¹é‡è®¾å¤‡æ•°æ®ä¸ŠæŠ¥å¤±è´¥: deviceId={}", deviceId, e);
            return ResponseDTO.error(UserErrorCode.SYSTEM_ERROR, "æ‰¹é‡æ•°æ®å¤„ç†å¤±è´¥");
        }
    }
}
```

#### 3. TCP/UDPæ•°æ®é‡‡é›†

```java
@Component
@Slf4j
public class TcpUdpDataCollector {

    @Resource
    private DataProcessor dataProcessor;

    @Resource
    private ConnectionManager connectionManager;

    /**
     * TCPæ•°æ®å¤„ç†å™¨
     */
    @Component
    public static class TcpDataHandler extends ChannelInboundHandlerAdapter {

        @Resource
        private DataProcessor dataProcessor;

        private final StringBuilder messageBuffer = new StringBuilder();

        @Override
        public void channelRead(ChannelHandlerContext ctx, Object msg) {
            try {
                ByteBuf byteBuf = (ByteBuf) msg;
                String receivedData = byteBuf.toString(CharsetUtil.UTF_8);

                // ç´¯ç§¯æ¶ˆæ¯æ•°æ®
                messageBuffer.append(receivedData);

                // æ£€æŸ¥æ˜¯å¦æ”¶åˆ°å®Œæ•´æ¶ˆæ¯ï¼ˆä»¥æ¢è¡Œç¬¦åˆ†éš”ï¼‰
                int messageEndIndex;
                while ((messageEndIndex = messageBuffer.indexOf("\n")) != -1) {
                    String completeMessage = messageBuffer.substring(0, messageEndIndex);
                    messageBuffer.delete(0, messageEndIndex + 1);

                    // å¤„ç†å®Œæ•´æ¶ˆæ¯
                    processTcpMessage(ctx, completeMessage);
                }

            } catch (Exception e) {
                log.error("å¤„ç†TCPæ•°æ®å¤±è´¥", e);
                ctx.close();
            }
        }

        private void processTcpMessage(ChannelHandlerContext ctx, String message) {
            try {
                // 1. è§£ææ¶ˆæ¯æ ¼å¼
                TcpDeviceMessage deviceMessage = TcpMessageParser.parse(message);

                // 2. æ„å»ºè®¾å¤‡æ•°æ®å¯¹è±¡
                DeviceData deviceData = DeviceData.builder()
                        .deviceId(deviceMessage.getDeviceId())
                        .timestamp(Instant.now())
                        .protocol("TCP")
                        .dataType(deviceMessage.getDataType())
                        .payload(deviceMessage.getPayload())
                        .connectionId(ctx.channel().id().asShortText())
                        .remoteAddress(ctx.channel().remoteAddress().toString())
                        .build();

                // 3. å¼‚æ­¥å¤„ç†æ•°æ®
                dataProcessor.process(deviceData);

            } catch (Exception e) {
                log.error("è§£æTCPæ¶ˆæ¯å¤±è´¥: message={}", message, e);
            }
        }
    }

    /**
     * UDPæ•°æ®å¤„ç†å™¨
     */
    @Component
    public static class UdpDataHandler extends SimpleChannelInboundHandler<DatagramPacket> {

        @Resource
        private DataProcessor dataProcessor;

        @Override
        protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket packet) {
            try {
                String receivedData = packet.content().toString(CharsetUtil.UTF_8);
                InetSocketAddress senderAddress = packet.sender();

                // 1. è§£æUDPæ¶ˆæ¯
                UdpDeviceMessage deviceMessage = UdpMessageParser.parse(receivedData);

                // 2. æ„å»ºè®¾å¤‡æ•°æ®å¯¹è±¡
                DeviceData deviceData = DeviceData.builder()
                        .deviceId(deviceMessage.getDeviceId())
                        .timestamp(Instant.now())
                        .protocol("UDP")
                        .dataType(deviceMessage.getDataType())
                        .payload(deviceMessage.getPayload())
                        .remoteAddress(senderAddress.getAddress().getHostAddress())
                        .remotePort(senderAddress.getPort())
                        .build();

                // 3. å¤„ç†æ•°æ®
                dataProcessor.process(deviceData);

            } catch (Exception e) {
                log.error("å¤„ç†UDPæ•°æ®å¤±è´¥", e);
            }
        }
    }
}
```

### ğŸ”§ æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯

#### æ•°æ®éªŒè¯æ¡†æ¶

```java
@Component
@Slf4j
public class DataValidator {

    @Resource
    private List<ValidationRule> validationRules;

    @Resource
    private SchemaRegistry schemaRegistry;

    /**
     * éªŒè¯è®¾å¤‡æ•°æ®
     */
    public ValidationResult validate(DeviceData deviceData) {
        try {
            ValidationResult result = ValidationResult.success();

            // 1. åŸºç¡€æ ¼å¼éªŒè¯
            ValidationResult basicValidation = validateBasicFormat(deviceData);
            if (!basicValidation.isValid()) {
                result.merge(basicValidation);
            }

            // 2. SchemaéªŒè¯
            ValidationResult schemaValidation = validateSchema(deviceData);
            if (!schemaValidation.isValid()) {
                result.merge(schemaValidation);
            }

            // 3. ä¸šåŠ¡è§„åˆ™éªŒè¯
            ValidationResult businessValidation = validateBusinessRules(deviceData);
            if (!businessValidation.isValid()) {
                result.merge(businessValidation);
            }

            // 4. æ•°æ®è´¨é‡æ£€æŸ¥
            ValidationResult qualityValidation = validateDataQuality(deviceData);
            if (!qualityValidation.isValid()) {
                result.merge(qualityValidation);
            }

            return result;

        } catch (Exception e) {
            log.error("æ•°æ®éªŒè¯å¼‚å¸¸: deviceId={}", deviceData.getDeviceId(), e);
            return ValidationResult.failed("éªŒè¯è¿‡ç¨‹å¼‚å¸¸: " + e.getMessage());
        }
    }

    /**
     * SchemaéªŒè¯
     */
    private ValidationResult validateSchema(DeviceData deviceData) {
        try {
            // 1. è·å–æ•°æ®Schema
            DataSchema schema = schemaRegistry.getSchema(deviceData.getDataType());
            if (schema == null) {
                return ValidationResult.failed("æœªæ‰¾åˆ°æ•°æ®ç±»å‹Schema: " + deviceData.getDataType());
            }

            // 2. è§£ææ•°æ®
            Object data = parsePayload(deviceData.getPayload(), schema.getFormat());

            // 3. SchemaéªŒè¯
            return JsonSchemaValidator.validate(data, schema.getSchema());

        } catch (Exception e) {
            return ValidationResult.failed("SchemaéªŒè¯å¤±è´¥: " + e.getMessage());
        }
    }

    /**
     * ä¸šåŠ¡è§„åˆ™éªŒè¯
     */
    private ValidationResult validateBusinessRules(DeviceData deviceData) {
        ValidationResult result = ValidationResult.success();

        for (ValidationRule rule : validationRules) {
            if (rule.supports(deviceData.getDataType())) {
                ValidationResult ruleResult = rule.validate(deviceData);
                if (!ruleResult.isValid()) {
                    result.merge(ruleResult);
                }
            }
        }

        return result;
    }
}
```

#### æ•°æ®æ¸…æ´—å’Œè½¬æ¢

```java
@Component
@Slf4j
public class DataCleaner {

    @Resource
    private Map<String, DataTransformer> transformers;

    @Resource
    private DataEnrichmentService enrichmentService;

    /**
     * æ¸…æ´—è®¾å¤‡æ•°æ®
     */
    public CleanedData clean(DeviceData deviceData) {
        try {
            // 1. æ•°æ®æ ‡å‡†åŒ–
            DeviceData normalizedData = normalizeData(deviceData);

            // 2. æ•°æ®è½¬æ¢
            DeviceData transformedData = transformData(normalizedData);

            // 3. æ•°æ®å¢å¼º
            DeviceData enrichedData = enrichData(transformedData);

            // 4. å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
            DeviceData filteredData = filterOutliers(enrichedData);

            return CleanedData.builder()
                    .originalData(deviceData)
                    .cleanedData(filteredData)
                    .transformationLog(getTransformationLog(deviceData, filteredData))
                    .build();

        } catch (Exception e) {
            log.error("æ•°æ®æ¸…æ´—å¤±è´¥: deviceId={}", deviceData.getDeviceId(), e);
            return CleanedData.failed(deviceData, e.getMessage());
        }
    }

    /**
     * æ•°æ®æ ‡å‡†åŒ–
     */
    private DeviceData normalizeData(DeviceData deviceData) {
        // 1. æ—¶é—´æˆ³æ ‡å‡†åŒ–
        Instant normalizedTimestamp = normalizeTimestamp(deviceData.getTimestamp());

        // 2. æ•°å€¼ç²¾åº¦æ ‡å‡†åŒ–
        Map<String, Object> normalizedPayload = normalizeNumericPrecision(deviceData.getPayload());

        // 3. å­—ç¬¦ç¼–ç æ ‡å‡†åŒ–
        String normalizedPayloadStr = normalizeCharacterEncoding(normalizedPayload);

        return deviceData.toBuilder()
                .timestamp(normalizedTimestamp)
                .payload(normalizedPayloadStr)
                .build();
    }

    /**
     * æ•°æ®è½¬æ¢
     */
    private DeviceData transformData(DeviceData deviceData) {
        DataTransformer transformer = transformers.get(deviceData.getDataType());
        if (transformer != null) {
            return transformer.transform(deviceData);
        }
        return deviceData;
    }

    /**
     * æ•°æ®å¢å¼º
     */
    private DeviceData enrichData(DeviceData deviceData) {
        try {
            // 1. æ·»åŠ è®¾å¤‡ä¿¡æ¯
            DeviceInfo deviceInfo = enrichmentService.getDeviceInfo(deviceData.getDeviceId());

            // 2. æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯
            LocationInfo locationInfo = enrichmentService.getLocationInfo(deviceData.getDeviceId());

            // 3. æ·»åŠ ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
            BusinessContext businessContext = enrichmentService.getBusinessContext(deviceData);

            Map<String, Object> enrichedMetadata = new HashMap<>(deviceData.getMetadata());
            enrichedMetadata.put("deviceInfo", deviceInfo);
            enrichedMetadata.put("locationInfo", locationInfo);
            enrichedMetadata.put("businessContext", businessContext);

            return deviceData.toBuilder()
                    .metadata(enrichedMetadata)
                    .build();

        } catch (Exception e) {
            log.warn("æ•°æ®å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: deviceId={}", deviceData.getDeviceId(), e);
            return deviceData;
        }
    }
}
```

---

## âš¡ æµå¤„ç†å¼•æ“è®¾è®¡

### ğŸ”„ Flinkæµå¤„ç†æ¶æ„

#### å®æ—¶æ•°æ®å¤„ç†ç®¡é“

```java
@Component
@Slf4j
public class FlinkDataProcessingPipeline {

    @Resource
    private StreamExecutionEnvironment env;

    @Resource
    private KafkaSource<String> kafkaSource;

    @Resource
    private SinkFunction<ProcessedData> influxDbSink;

    @Resource
    private SinkFunction<AlertEvent> alertSink;

    /**
     * åˆ›å»ºå®æ—¶æ•°æ®å¤„ç†ç®¡é“
     */
    public void buildPipeline() {
        try {
            // 1. é…ç½®æ‰§è¡Œç¯å¢ƒ
            env.setParallelism(4);
            env.enableCheckpointing(60000); // 1åˆ†é’Ÿæ£€æŸ¥ç‚¹
            env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

            // 2. åˆ›å»ºæ•°æ®æº
            DataStream<String> rawStream = kafkaSource
                    .setStartingOffsets(OffsetsInitializer.latest())
                    .setBounded(OffsetsInitializer.unbounded())
                    .build();

            // 3. æ•°æ®æµå¤„ç†ç®¡é“
            DataStream<ProcessedData> processedStream = rawStream
                    // ååºåˆ—åŒ–JSONæ•°æ®
                    .map(this::deserializeDeviceData)
                    .name("Deserialize-Device-Data")
                    // æ•°æ®éªŒè¯
                    .filter(this::validateDeviceData)
                    .name("Validate-Device-Data")
                    // æ•°æ®æ¸…æ´—
                    .map(this::cleanDeviceData)
                    .name("Clean-Device-Data")
                    // æ•°æ®è½¬æ¢
                    .map(this::transformDeviceData)
                    .name("Transform-Device-Data")
                    // å¼‚å¸¸æ£€æµ‹
                    .process(this::detectAnomalies)
                    .name("Detect-Anomalies");

            // 4. åˆ†æµå¤„ç†
            DataStream<ProcessedData> normalDataStream = processedStream
                    .filter(data -> !data.isAnomaly())
                    .name("Filter-Normal-Data");

            DataStream<ProcessedData> anomalyDataStream = processedStream
                    .filter(ProcessedData::isAnomaly)
                    .name("Filter-Anomaly-Data");

            // 5. æ­£å¸¸æ•°æ®å¤„ç†
            normalDataStream
                    // å®æ—¶èšåˆ
                    .keyBy(ProcessedData::getDeviceId)
                    .window(TumblingProcessingTimeWindows.of(Time.minutes(1)))
                    .aggregate(new DeviceDataAggregator())
                    .name("Aggregate-Normal-Data")
                    // å†™å…¥æ—¶åºæ•°æ®åº“
                    .addSink(influxDbSink)
                    .name("Write-To-InfluxDB");

            // 6. å¼‚å¸¸æ•°æ®å¤„ç†
            anomalyDataStream
                    // ç”Ÿæˆå‘Šè­¦
                    .map(this::generateAlert)
                    .name("Generate-Alert")
                    // å‘é€å‘Šè­¦
                    .addSink(alertSink)
                    .name("Send-Alert");

            // 7. æ‰§è¡Œä½œä¸š
            env.execute("IOT-Device-Data-Processing-Pipeline");

        } catch (Exception e) {
            log.error("åˆ›å»ºFlinkæ•°æ®å¤„ç†ç®¡é“å¤±è´¥", e);
            throw new PipelineCreationException("ç®¡é“åˆ›å»ºå¤±è´¥", e);
        }
    }

    /**
     * è®¾å¤‡æ•°æ®èšåˆå™¨
     */
    public static class DeviceDataAggregator
            implements AggregateFunction<ProcessedData, DeviceDataAccumulator, ProcessedData> {

        @Override
        public DeviceDataAccumulator createAccumulator() {
            return new DeviceDataAccumulator();
        }

        @Override
        public DeviceDataAccumulator add(ProcessedData data, DeviceDataAccumulator accumulator) {
            accumulator.add(data);
            return accumulator;
        }

        @Override
        public ProcessedData getResult(DeviceDataAccumulator accumulator) {
            return accumulator.buildAggregatedData();
        }

        @Override
        public DeviceDataAccumulator merge(DeviceDataAccumulator a, DeviceDataAccumulator b) {
            return a.merge(b);
        }
    }
}
```

#### å¤æ‚äº‹ä»¶å¤„ç†

```java
@Component
@Slf4j
public class ComplexEventProcessor {

    @Resource
    private CEP cep;

    @Resource
    private PatternFactory patternFactory;

    /**
     * è®¾å¤‡æ•…éšœæ£€æµ‹æ¨¡å¼
     */
    public void detectDeviceFailures(DataStream<ProcessedData> dataStream) {
        // 1. å®šä¹‰æ•…éšœæ£€æµ‹æ¨¡å¼
        Pattern<ProcessedData, ?> failurePattern = Pattern.<ProcessedData>begin("first")
                .where(new SimpleCondition<ProcessedData>() {
                    @Override
                    public boolean filter(ProcessedData data) {
                        return data.getMetricValue("error_rate") > 0.1; // é”™è¯¯ç‡>10%
                    }
                })
                .next("second")
                .where(new SimpleCondition<ProcessedData>() {
                    @Override
                    public boolean filter(ProcessedData data) {
                        return data.getMetricValue("response_time") > 5000; // å“åº”æ—¶é—´>5s
                    }
                })
                .within(Time.seconds(30)); // 30ç§’å†…å‘ç”Ÿ

        // 2. åº”ç”¨æ¨¡å¼æ£€æµ‹
        PatternStream<ProcessedData> patternStream = CEP.pattern(dataStream.keyBy(ProcessedData::getDeviceId), failurePattern);

        // 3. å¤„ç†åŒ¹é…çš„äº‹ä»¶
        patternStream.select(new PatternSelectFunction<ProcessedData, DeviceFailureEvent>() {
            @Override
            public DeviceFailureEvent select(Map<String, List<ProcessedData>> pattern) {
                List<ProcessedData> firstEvents = pattern.get("first");
                List<ProcessedData> secondEvents = pattern.get("second");

                return DeviceFailureEvent.builder()
                        .deviceId(firstEvents.get(0).getDeviceId())
                        .firstEventTime(firstEvents.get(0).getTimestamp())
                        .secondEventTime(secondEvents.get(0).getTimestamp())
                        .failureType("PERFORMANCE_DEGRADATION")
                        .severity("HIGH")
                        .description("è®¾å¤‡æ€§èƒ½æ˜¾è‘—ä¸‹é™")
                        .build();
            }
        }).addSink(new SinkFunction<DeviceFailureEvent>() {
            @Override
            public void invoke(DeviceFailureEvent event, Context context) {
                handleDeviceFailure(event);
            }
        });
    }

    /**
     * è®¾å¤‡ç¦»çº¿æ£€æµ‹æ¨¡å¼
     */
    public void detectDeviceOffline(DataStream<ProcessedData> dataStream) {
        // 1. å®šä¹‰ç¦»çº¿æ£€æµ‹æ¨¡å¼ï¼ˆ5åˆ†é’Ÿå†…æ²¡æœ‰æ•°æ®ï¼‰
        Pattern<ProcessedData, ?> offlinePattern = Pattern.<ProcessedData>begin("offline")
                .where(new SimpleCondition<ProcessedData>() {
                    @Override
                    public boolean filter(ProcessedData data) {
                        return true; // ä»»ä½•æ•°æ®éƒ½ä¼šè§¦å‘æ¨¡å¼
                    }
                })
                .notNext("any")
                .within(Time.minutes(5));

        // 2. åº”ç”¨æ¨¡å¼æ£€æµ‹
        PatternStream<ProcessedData> patternStream = CEP.pattern(
            dataStream.keyBy(ProcessedData::getDeviceId), offlinePattern);

        // 3. å¤„ç†ç¦»çº¿äº‹ä»¶
        patternStream.select(new PatternSelectFunction<ProcessedData, DeviceOfflineEvent>() {
            @Override
            public DeviceOfflineEvent select(Map<String, List<ProcessedData>> pattern) {
                List<ProcessedData> offlineEvents = pattern.get("offline");
                ProcessedData lastEvent = offlineEvents.get(0);

                return DeviceOfflineEvent.builder()
                        .deviceId(lastEvent.getDeviceId())
                        .lastSeenTime(lastEvent.getTimestamp())
                        .offlineDuration(Duration.ofMinutes(5))
                        .severity("MEDIUM")
                        .description("è®¾å¤‡ç¦»çº¿è¶…è¿‡5åˆ†é’Ÿ")
                        .build();
            }
        }).addSink(new SinkFunction<DeviceOfflineEvent>() {
            @Override
            public void invoke(DeviceOfflineEvent event, Context context) {
                handleDeviceOffline(event);
            }
        });
    }
}
```

---

## ğŸ—„ï¸ æ•°æ®å­˜å‚¨æ¶æ„è®¾è®¡

### ğŸ“Š å¤šå±‚æ•°æ®å­˜å‚¨

#### 1. æ—¶åºæ•°æ®åº“ (InfluxDB)

```java
@Component
@Slf4j
public class TimeSeriesDataStorage {

    @Resource
    private InfluxDBTemplate influxDBTemplate;

    @Value("${influxdb.database:device_metrics}")
    private String database;

    @Value("${influxdb.retention.policy:autogen}")
    private String retentionPolicy;

    /**
     * å†™å…¥è®¾å¤‡æŒ‡æ ‡æ•°æ®
     */
    @Async
    public CompletableFuture<Void> writeDeviceMetrics(List<DeviceMetric> metrics) {
        return CompletableFuture.runAsync(() -> {
            try {
                List<Point> points = metrics.stream()
                        .map(this::convertToPoint)
                        .collect(Collectors.toList());

                influxDBTemplate.write(points, database, retentionPolicy);
                log.debug("å†™å…¥è®¾å¤‡æŒ‡æ ‡æ•°æ®æˆåŠŸï¼Œæ•°é‡: {}", points.size());

            } catch (Exception e) {
                log.error("å†™å…¥è®¾å¤‡æŒ‡æ ‡æ•°æ®å¤±è´¥", e);
            }
        });
    }

    /**
     * æŸ¥è¯¢è®¾å¤‡æŒ‡æ ‡æ•°æ®
     */
    public List<DeviceMetric> queryDeviceMetrics(DeviceMetricQuery query) {
        try {
            Query queryBuilder = QueryBuilder
                    .select()
                    .column("value")
                    .from(query.getMeasurement())
                    .where(TagCondition.eq("device_id", query.getDeviceId()))
                    .and(TimeCondition.between(query.getStartTime(), query.getEndTime()));

            // æ·»åŠ èšåˆæ¡ä»¶
            if (query.getAggregation() != null) {
                queryBuilder = applyAggregation(queryBuilder, query.getAggregation());
            }

            // æ·»åŠ åˆ†ç»„æ¡ä»¶
            if (query.getGroupByTags() != null) {
                queryBuilder.groupBy(query.getGroupByTags().toArray(new String[0]));
            }

            QueryResult queryResult = influxDBTemplate.query(queryBuilder.build(), database);
            return convertQueryResult(queryResult);

        } catch (Exception e) {
            log.error("æŸ¥è¯¢è®¾å¤‡æŒ‡æ ‡æ•°æ®å¤±è´¥: query={}", query, e);
            return Collections.emptyList();
        }
    }

    /**
     * åˆ›å»ºè¿ç»­æŸ¥è¯¢
     */
    public void createContinuousQueries() {
        try {
            // 1. åˆ›å»º1åˆ†é’Ÿèšåˆè¿ç»­æŸ¥è¯¢
            String cq1Minute = "CREATE CONTINUOUS QUERY \"cq_1m\" ON \"" + database + "\" " +
                    "BEGIN SELECT mean(\"value\") AS \"value_mean\", " +
                    "max(\"value\") AS \"value_max\", " +
                    "min(\"value\") AS \"value_min\", " +
                    "count(\"value\") AS \"value_count\" " +
                    "INTO \"device_metrics_1m\" " +
                    "FROM \"device_metrics\" " +
                    "GROUP BY time(1m), \"device_id\", \"metric_type\" END";

            influxDBTemplate.createContinuousQuery(cq1Minute);

            // 2. åˆ›å»º1å°æ—¶èšåˆè¿ç»­æŸ¥è¯¢
            String cq1Hour = "CREATE CONTINUOUS QUERY \"cq_1h\" ON \"" + database + "\" " +
                    "BEGIN SELECT mean(\"value\") AS \"value_mean\", " +
                    "max(\"value\") AS \"value_max\", " +
                    "min(\"value\") AS \"value_min\", " +
                    "count(\"value\") AS \"value_count\" " +
                    "INTO \"device_metrics_1h\" " +
                    "FROM \"device_metrics_1m\" " +
                    "GROUP BY time(1h), \"device_id\", \"metric_type\" END";

            influxDBTemplate.createContinuousQuery(cq1Hour);

            // 3. åˆ›å»º1å¤©èšåˆè¿ç»­æŸ¥è¯¢
            String cq1Day = "CREATE CONTINUOUS QUERY \"cq_1d\" ON \"" + database + "\" " +
                    "BEGIN SELECT mean(\"value\") AS \"value_mean\", " +
                    "max(\"value\") AS \"value_max\", " +
                    "min(\"value\") AS \"value_min\", " +
                    "count(\"value\") AS \"value_count\" " +
                    "INTO \"device_metrics_1d\" " +
                    "FROM \"device_metrics_1h\" " +
                    "GROUP BY time(1d), \"device_id\", \"metric_type\" END";

            influxDBTemplate.createContinuousQuery(cq1Day);

            log.info("åˆ›å»ºè¿ç»­æŸ¥è¯¢æˆåŠŸ");

        } catch (Exception e) {
            log.error("åˆ›å»ºè¿ç»­æŸ¥è¯¢å¤±è´¥", e);
        }
    }

    /**
     * è½¬æ¢ä¸ºInfluxDB Point
     */
    private Point convertToPoint(DeviceMetric metric) {
        Point.Builder builder = Point.measurement(metric.getMeasurement())
                .time(metric.getTimestamp().toEpochMilli(), TimeUnit.MILLISECONDS)
                .tag("device_id", metric.getDeviceId())
                .tag("device_type", metric.getDeviceType())
                .tag("metric_type", metric.getMetricType())
                .tag("location", metric.getLocation())
                .addField("value", metric.getValue());

        // æ·»åŠ é¢å¤–æ ‡ç­¾
        if (metric.getAdditionalTags() != null) {
            metric.getAdditionalTags().forEach(builder::tag);
        }

        // æ·»åŠ é¢å¤–å­—æ®µ
        if (metric.getAdditionalFields() != null) {
            metric.getAdditionalFields().forEach(builder::addField);
        }

        return builder.build();
    }
}
```

#### 2. åˆ†ææ•°æ®åº“ (ClickHouse)

```java
@Component
@Slf4j
public class AnalyticalDataStorage {

    @Resource
    private JdbcTemplate clickHouseTemplate;

    /**
     * æ‰¹é‡å†™å…¥åˆ†ææ•°æ®
     */
    @Async
    public CompletableFuture<Void> batchInsertAnalyticalData(List<AnalyticalData> dataList) {
        return CompletableFuture.runAsync(() -> {
            try {
                String sql = buildInsertSQL();
                clickHouseTemplate.batchUpdate(sql, dataList, this::prepareStatement);
                log.debug("æ‰¹é‡å†™å…¥åˆ†ææ•°æ®æˆåŠŸï¼Œæ•°é‡: {}", dataList.size());

            } catch (Exception e) {
                log.error("æ‰¹é‡å†™å…¥åˆ†ææ•°æ®å¤±è´¥", e);
            }
        });
    }

    /**
     * æ„å»ºæ’å…¥SQL
     */
    private String buildInsertSQL() {
        return "INSERT INTO device_analytical_data (" +
                "device_id, device_type, timestamp, metric_type, value, " +
                "metadata, created_at) VALUES (?, ?, ?, ?, ?, ?, ?)";
    }

    /**
     * å‡†å¤‡è¯­å¥å‚æ•°
     */
    private void prepareStatement(PreparedStatement ps, AnalyticalData data) throws SQLException {
        ps.setString(1, data.getDeviceId());
        ps.setString(2, data.getDeviceType());
        ps.setTimestamp(3, Timestamp.from(data.getTimestamp()));
        ps.setString(4, data.getMetricType());
        ps.setDouble(5, data.getValue());
        ps.setString(6, data.getMetadataJson());
        ps.setTimestamp(7, Timestamp.from(Instant.now()));
    }

    /**
     * åˆ›å»ºåˆ†ææ•°æ®è¡¨
     */
    public void createAnalyticalTables() {
        try {
            // 1. è®¾å¤‡åˆ†ææ•°æ®è¡¨
            String createDeviceAnalyticalTable = "CREATE TABLE IF NOT EXISTS device_analytical_data (" +
                    "device_id String," +
                    "device_type String," +
                    "timestamp DateTime," +
                    "metric_type String," +
                    "value Float64," +
                    "metadata String," +
                    "created_at DateTime DEFAULT now()" +
                    ") ENGINE = MergeTree() " +
                    "PARTITION BY toYYYYMM(timestamp) " +
                    "ORDER BY (device_id, timestamp, metric_type) " +
                    "TTL timestamp + INTERVAL 1 YEAR";

            clickHouseTemplate.execute(createDeviceAnalyticalTable);

            // 2. è®¾å¤‡ç»Ÿè®¡æ•°æ®è¡¨
            String createDeviceStatsTable = "CREATE TABLE IF NOT EXISTS device_stats (" +
                    "device_id String," +
                    "device_type String," +
                    "date Date," +
                    "metric_type String," +
                    "avg_value Float64," +
                    "min_value Float64," +
                    "max_value Float64," +
                    "count_value UInt64," +
                    "updated_at DateTime DEFAULT now()" +
                    ") ENGINE = ReplacingMergeTree() " +
                    "PARTITION BY toYYYYMM(date) " +
                    "ORDER BY (device_id, date, metric_type)";

            clickHouseTemplate.execute(createDeviceStatsTable);

            log.info("åˆ›å»ºåˆ†ææ•°æ®è¡¨æˆåŠŸ");

        } catch (Exception e) {
            log.error("åˆ›å»ºåˆ†ææ•°æ®è¡¨å¤±è´¥", e);
        }
    }
}
```

#### 3. æ–‡æ¡£æ•°æ®åº“ (MongoDB)

```java
@Component
@Slf4j
public class DocumentDataStorage {

    @Resource
    private MongoTemplate mongoTemplate;

    /**
     * å­˜å‚¨è®¾å¤‡äº‹ä»¶æ—¥å¿—
     */
    @Async
    public CompletableFuture<Void> saveDeviceEvent(DeviceEventLog eventLog) {
        return CompletableFuture.runAsync(() -> {
            try {
                mongoTemplate.save(eventLog, "device_event_logs");
                log.debug("ä¿å­˜è®¾å¤‡äº‹ä»¶æ—¥å¿—æˆåŠŸ: eventId={}", eventLog.getEventId());

            } catch (Exception e) {
                log.error("ä¿å­˜è®¾å¤‡äº‹ä»¶æ—¥å¿—å¤±è´¥: eventId={}", eventLog.getEventId(), e);
            }
        });
    }

    /**
     * æ‰¹é‡å­˜å‚¨è®¾å¤‡äº‹ä»¶æ—¥å¿—
     */
    @Async
    public CompletableFuture<Void> batchSaveDeviceEvents(List<DeviceEventLog> eventLogs) {
        return CompletableFuture.runAsync(() -> {
            try {
                mongoTemplate.insertAll(eventLogs, "device_event_logs");
                log.debug("æ‰¹é‡ä¿å­˜è®¾å¤‡äº‹ä»¶æ—¥å¿—æˆåŠŸï¼Œæ•°é‡: {}", eventLogs.size());

            } catch (Exception e) {
                log.error("æ‰¹é‡ä¿å­˜è®¾å¤‡äº‹ä»¶æ—¥å¿—å¤±è´¥", e);
            }
        });
    }

    /**
     * æŸ¥è¯¢è®¾å¤‡äº‹ä»¶æ—¥å¿—
     */
    public List<DeviceEventLog> queryDeviceEventLogs(DeviceEventQuery query) {
        try {
            Query mongoQuery = new Query();

            // è®¾å¤‡IDæ¡ä»¶
            if (StringUtils.hasText(query.getDeviceId())) {
                mongoQuery.addCriteria(Criteria.where("deviceId").is(query.getDeviceId()));
            }

            // äº‹ä»¶ç±»å‹æ¡ä»¶
            if (StringUtils.hasText(query.getEventType())) {
                mongoQuery.addCriteria(Criteria.where("eventType").is(query.getEventType()));
            }

            // æ—¶é—´èŒƒå›´æ¡ä»¶
            if (query.getStartTime() != null && query.getEndTime() != null) {
                mongoQuery.addCriteria(Criteria.where("eventTime")
                        .gte(query.getStartTime())
                        .lte(query.getEndTime()));
            }

            // åˆ†é¡µæ¡ä»¶
            mongoQuery.with(PageRequest.of(query.getPage(), query.getSize()));

            // æ’åºæ¡ä»¶
            mongoQuery.with(Sort.by(Sort.Direction.DESC, "eventTime"));

            return mongoTemplate.find(mongoQuery, DeviceEventLog.class, "device_event_logs");

        } catch (Exception e) {
            log.error("æŸ¥è¯¢è®¾å¤‡äº‹ä»¶æ—¥å¿—å¤±è´¥: query={}", query, e);
            return Collections.emptyList();
        }
    }

    /**
     * åˆ›å»ºç´¢å¼•
     */
    public void createIndexes() {
        try {
            // 1. è®¾å¤‡äº‹ä»¶æ—¥å¿—ç´¢å¼•
            mongoTemplate.indexOps("device_event_logs")
                    .ensureIndex(new Index().on("deviceId", Sort.Direction.ASC)
                            .on("eventTime", Sort.Direction.DESC));

            mongoTemplate.indexOps("device_event_logs")
                    .ensureIndex(new Index().on("eventType", Sort.Direction.ASC)
                            .on("eventTime", Sort.Direction.DESC));

            // 2. TTLç´¢å¼•ï¼ˆäº‹ä»¶æ—¥å¿—ä¿ç•™30å¤©ï¼‰
            mongoTemplate.indexOps("device_event_logs")
                    .ensureIndex(new Index().on("eventTime", Sort.Direction.ASC)
                            .expire(30, TimeUnit.DAYS));

            log.info("åˆ›å»ºMongoDBç´¢å¼•æˆåŠŸ");

        } catch (Exception e) {
            log.error("åˆ›å»ºMongoDBç´¢å¼•å¤±è´¥", e);
        }
    }
}
```

---

## ğŸ¤– æ™ºèƒ½åˆ†æå’Œæœºå™¨å­¦ä¹ 

### ğŸ§  æœºå™¨å­¦ä¹ ç®¡é“

#### è®¾å¤‡å¼‚å¸¸æ£€æµ‹æ¨¡å‹

```java
@Component
@Slf4j
public class DeviceAnomalyDetectionService {

    @Resource
    private ModelRepository modelRepository;

    @Resource
    private TrainingDataService trainingDataService;

    @Resource
    private PredictionService predictionService;

    /**
     * è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹
     */
    @Async
    public CompletableFuture<TrainingResult> trainAnomalyDetectionModel(
            String deviceId, String metricType, TrainingConfig config) {

        return CompletableFuture.supplyAsync(() -> {
            try {
                log.info("å¼€å§‹è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹: deviceId={}, metricType={}", deviceId, metricType);

                // 1. è·å–è®­ç»ƒæ•°æ®
                List<TrainingDataPoint> trainingData = trainingDataService
                        .getTrainingData(deviceId, metricType, config.getTrainingPeriod());

                if (CollectionUtils.isEmpty(trainingData)) {
                    return TrainingResult.failed("è®­ç»ƒæ•°æ®ä¸è¶³");
                }

                // 2. æ•°æ®é¢„å¤„ç†
                List<TrainingDataPoint> processedData = preprocessTrainingData(trainingData);

                // 3. ç‰¹å¾å·¥ç¨‹
                List<FeatureVector> featureVectors = extractFeatures(processedData);

                // 4. æ¨¡å‹è®­ç»ƒ
                IsolationForestModel model = trainIsolationForestModel(featureVectors, config);

                // 5. æ¨¡å‹éªŒè¯
                ValidationResult validationResult = validateModel(model, processedData);

                // 6. ä¿å­˜æ¨¡å‹
                String modelId = saveModel(deviceId, metricType, model, validationResult);

                return TrainingResult.success(modelId, validationResult);

            } catch (Exception e) {
                log.error("è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹å¤±è´¥: deviceId={}, metricType={}", deviceId, metricType, e);
                return TrainingResult.failed("æ¨¡å‹è®­ç»ƒå¼‚å¸¸: " + e.getMessage());
            }
        });
    }

    /**
     * å®æ—¶å¼‚å¸¸æ£€æµ‹
     */
    public CompletableFuture<AnomalyDetectionResult> detectAnomalies(
            String deviceId, String metricType, List<DeviceMetric> recentMetrics) {

        return CompletableFuture.supplyAsync(() -> {
            try {
                // 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
                AnomalyDetectionModel model = modelRepository.getLatestModel(deviceId, metricType);
                if (model == null) {
                    return AnomalyDetectionResult.failed("æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹");
                }

                // 2. æ•°æ®é¢„å¤„ç†
                List<FeatureVector> featureVectors = extractFeaturesFromMetrics(recentMetrics);

                // 3. å¼‚å¸¸æ£€æµ‹
                List<AnomalyScore> anomalyScores = new ArrayList<>();
                for (FeatureVector vector : featureVectors) {
                    double score = model.predict(vector);
                    anomalyScores.add(AnomalyScore.builder()
                            .timestamp(vector.getTimestamp())
                            .score(score)
                            .isAnomaly(score > model.getThreshold())
                            .build());
                }

                // 4. ç»“æœèšåˆ
                return AnomalyDetectionResult.builder()
                        .deviceId(deviceId)
                        .metricType(metricType)
                        .anomalyScores(anomalyScores)
                        .maxAnomalyScore(anomalyScores.stream()
                                .mapToDouble(AnomalyScore::getScore)
                                .max()
                                .orElse(0.0))
                        .hasAnomalies(anomalyScores.stream().anyMatch(AnomalyScore::isAnomaly))
                        .detectionTime(Instant.now())
                        .build();

            } catch (Exception e) {
                log.error("å¼‚å¸¸æ£€æµ‹å¤±è´¥: deviceId={}, metricType={}", deviceId, metricType, e);
                return AnomalyDetectionResult.failed("å¼‚å¸¸æ£€æµ‹å¼‚å¸¸: " + e.getMessage());
            }
        });
    }

    /**
     * è®­ç»ƒå­¤ç«‹æ£®æ—æ¨¡å‹
     */
    private IsolationForestModel trainIsolationForestModel(
            List<FeatureVector> featureVectors, TrainingConfig config) {

        // ç‰¹å¾çŸ©é˜µ
        double[][] features = featureVectors.stream()
                .map(FeatureVector::getFeatures)
                .toArray(double[][]::new);

        // åˆ›å»ºå¹¶é…ç½®å­¤ç«‹æ£®æ—
        IsolationForest forest = new IsolationForest();
        forest.setNumTrees(config.getNumTrees());
        forest.setMaxSamples(config.getMaxSamples());
        forest.setMaxFeatures(config.getMaxFeatures());
        forest.setContamination(config.getContamination());
        forest.setBootstrap(config.isBootstrap());
        forest.setRandomState(config.getRandomSeed());

        // è®­ç»ƒæ¨¡å‹
        forest.fit(features);

        return new IsolationForestModel(forest, config);
    }
}
```

#### è®¾å¤‡é¢„æµ‹æ€§ç»´æŠ¤æ¨¡å‹

```java
@Component
@Slf4j
public class PredictiveMaintenanceService {

    @Resource
    private DataMiningService dataMiningService;

    @Resource
    private MaintenanceRecommendationEngine recommendationEngine;

    /**
     * è®¾å¤‡å¥åº·åº¦é¢„æµ‹
     */
    public CompletableFuture<HealthPrediction> predictDeviceHealth(
            String deviceId, Duration predictionHorizon) {

        return CompletableFuture.supplyAsync(() -> {
            try {
                // 1. è·å–å†å²æ•°æ®
                List<DeviceHealthData> healthData = dataMiningService
                        .getDeviceHealthHistory(deviceId, Duration.ofDays(90));

                if (CollectionUtils.isEmpty(healthData)) {
                    return HealthPrediction.insufficientData("å†å²æ•°æ®ä¸è¶³");
                }

                // 2. ç‰¹å¾æå–
                List<HealthFeature> features = extractHealthFeatures(healthData);

                // 3. æ—¶é—´åºåˆ—é¢„æµ‹
                TimeSeriesPrediction healthScorePrediction = predictHealthScore(
                    features, predictionHorizon);

                // 4. æ•…éšœé£é™©é¢„æµ‹
                FailureRiskPrediction failureRiskPrediction = predictFailureRisk(
                    features, predictionHorizon);

                // 5. ç»´æŠ¤å»ºè®®ç”Ÿæˆ
                List<MaintenanceRecommendation> recommendations =
                    recommendationEngine.generateRecommendations(
                        deviceId, healthScorePrediction, failureRiskPrediction);

                return HealthPrediction.builder()
                        .deviceId(deviceId)
                        .predictionHorizon(predictionHorizon)
                        .healthScorePrediction(healthScorePrediction)
                        .failureRiskPrediction(failureRiskPrediction)
                        .recommendations(recommendations)
                        .predictionTime(Instant.now())
                        .confidence(calculatePredictionConfidence(features))
                        .build();

            } catch (Exception e) {
                log.error("è®¾å¤‡å¥åº·åº¦é¢„æµ‹å¤±è´¥: deviceId={}", deviceId, e);
                return HealthPrediction.failed("é¢„æµ‹å¼‚å¸¸: " + e.getMessage());
            }
        });
    }

    /**
     * å¥åº·åº¦è¯„åˆ†é¢„æµ‹
     */
    private TimeSeriesPrediction predictHealthScore(
            List<HealthFeature> features, Duration horizon) {

        // ä½¿ç”¨LSTMç¥ç»ç½‘ç»œè¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹
        LSTMModel model = new LSTMModel();
        model.setInputSize(features.size());
        model.setHiddenSize(64);
        model.setOutputSize(1);
        model.setSequenceLength(24); // ä½¿ç”¨24å°æ—¶å†å²æ•°æ®

        // å‡†å¤‡è®­ç»ƒæ•°æ®
        double[][] trainingData = prepareTimeSeriesData(features);

        // è®­ç»ƒæ¨¡å‹
        model.train(trainingData);

        // è¿›è¡Œé¢„æµ‹
        int predictionSteps = (int) horizon.toHours();
        double[] predictions = model.predict(predictionSteps);

        return TimeSeriesPrediction.builder()
                .predictions(predictions)
                .predictionSteps(predictionSteps)
                .modelAccuracy(model.getAccuracy())
                .build();
    }

    /**
     * æ•…éšœé£é™©é¢„æµ‹
     */
    private FailureRiskPrediction predictFailureRisk(
            List<HealthFeature> features, Duration horizon) {

        // ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨é¢„æµ‹æ•…éšœæ¦‚ç‡
        RandomForestClassifier classifier = new RandomForestClassifier();
        classifier.setNumTrees(100);
        classifier.setMaxDepth(10);

        // ç‰¹å¾å·¥ç¨‹
        double[][] featureMatrix = extractFailureRiskFeatures(features);

        // é¢„æµ‹æ•…éšœæ¦‚ç‡
        double[] failureProbabilities = classifier.predictProba(featureMatrix);

        return FailureRiskPrediction.builder()
                .failureProbabilities(failureProbabilities)
                .maxFailureProbability(Arrays.stream(failureProbabilities).max().orElse(0.0))
                .riskLevel(calculateRiskLevel(failureProbabilities))
                .build();
    }
}
```

---

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### ğŸ“ˆ æ•°æ®å¤„ç†ç›‘æ§

```java
@Component
@Slf4j
public class DataProcessingMonitor {

    @Resource
    private MeterRegistry meterRegistry;

    private final Counter dataIngestionCounter;
    private final Counter dataProcessingErrorCounter;
    private final Timer processingLatencyTimer;
    private final Gauge queueSizeGauge;
    private final Gauge throughputGauge;

    public DataProcessingMonitor(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;

        this.dataIngestionCounter = Counter.builder("data.ingestion.total")
                .description("æ•°æ®æ¥æ”¶æ€»æ•°")
                .tag("protocol", "unknown")
                .tag("data_type", "unknown")
                .register(meterRegistry);

        this.dataProcessingErrorCounter = Counter.builder("data.processing.errors.total")
                .description("æ•°æ®å¤„ç†é”™è¯¯æ€»æ•°")
                .tag("error_type", "unknown")
                .register(meterRegistry);

        this.processingLatencyTimer = Timer.builder("data.processing.latency")
                .description("æ•°æ®å¤„ç†å»¶è¿Ÿ")
                .tag("stage", "unknown")
                .register(meterRegistry);

        this.queueSizeGauge = Gauge.builder("data.queue.size")
                .description("æ•°æ®é˜Ÿåˆ—å¤§å°")
                .tag("queue_name", "unknown")
                .register(meterRegistry);

        this.throughputGauge = Gauge.builder("data.processing.throughput")
                .description("æ•°æ®å¤„ç†ååé‡")
                .register(meterRegistry);
    }

    /**
     * è®°å½•æ•°æ®æ¥æ”¶
     */
    public void recordDataIngestion(String protocol, String dataType, long count) {
        dataIngestionCounter.increment(
            Tags.of("protocol", protocol, "data_type", dataType)
        );
    }

    /**
     * è®°å½•å¤„ç†é”™è¯¯
     */
    public void recordProcessingError(String errorType) {
        dataProcessingErrorCounter.increment(
            Tags.of("error_type", errorType)
        );
    }

    /**
     * è®°å½•å¤„ç†å»¶è¿Ÿ
     */
    public void recordProcessingLatency(String stage, long durationMs) {
        processingLatencyTimer.record(durationMs, TimeUnit.MILLISECONDS,
            Tags.of("stage", stage));
    }

    /**
     * æ›´æ–°é˜Ÿåˆ—å¤§å°
     */
    public void updateQueueSize(String queueName, long size) {
        queueSizeGauge.set(size, Tags.of("queue_name", queueName));
    }

    /**
     * æ›´æ–°å¤„ç†ååé‡
     */
    public void updateThroughput(double throughput) {
        throughputGauge.set(throughput);
    }
}
```

### ğŸ” æ•°æ®è´¨é‡ç›‘æ§

```java
@Component
@Slf4j
public class DataQualityMonitor {

    @Resource
    private DataQualityMetrics metrics;

    /**
     * æ•°æ®è´¨é‡æ£€æŸ¥
     */
    @Scheduled(fixedRate = 60000) // æ¯åˆ†é’Ÿæ‰§è¡Œ
    public void performDataQualityCheck() {
        try {
            // 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            double completenessScore = checkDataCompleteness();

            // 2. æ•°æ®å‡†ç¡®æ€§æ£€æŸ¥
            double accuracyScore = checkDataAccuracy();

            // 3. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
            double consistencyScore = checkDataConsistency();

            // 4. æ•°æ®åŠæ—¶æ€§æ£€æŸ¥
            double timelinessScore = checkDataTimeliness();

            // 5. è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
            double overallQualityScore = (completenessScore + accuracyScore +
                                        consistencyScore + timelinessScore) / 4.0;

            // 6. è®°å½•è´¨é‡æŒ‡æ ‡
            metrics.recordDataQualityMetrics(completenessScore, accuracyScore,
                                         consistencyScore, timelinessScore, overallQualityScore);

            // 7. è´¨é‡å‘Šè­¦
            if (overallQualityScore < 0.8) {
                sendDataQualityAlert(overallQualityScore);
            }

        } catch (Exception e) {
            log.error("æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥", e);
        }
    }

    /**
     * æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
     */
    private double checkDataCompleteness() {
        try {
            // æ£€æŸ¥å¿…å¡«å­—æ®µçš„å®Œæ•´ç‡
            String sql = "SELECT COUNT(*) FROM device_data WHERE " +
                        "device_id IS NOT NULL AND timestamp IS NOT NULL AND payload IS NOT NULL";
            Long completeRecords = jdbcTemplate.queryForObject(sql, Long.class);

            String totalSql = "SELECT COUNT(*) FROM device_data";
            Long totalRecords = jdbcTemplate.queryForObject(totalSql, Long.class);

            return totalRecords > 0 ? (double) completeRecords / totalRecords : 0.0;

        } catch (Exception e) {
            log.error("æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¤±è´¥", e);
            return 0.0;
        }
    }

    /**
     * æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§
     */
    private double checkDataAccuracy() {
        try {
            // æ£€æŸ¥æ•°æ®æ ¼å¼å‡†ç¡®æ€§
            String sql = "SELECT COUNT(*) FROM device_data WHERE " +
                        "JSON_VALID(payload) = 1 AND timestamp > NOW() - INTERVAL 1 HOUR";
            Long accurateRecords = jdbcTemplate.queryForObject(sql, Long.class);

            String totalSql = "SELECT COUNT(*) FROM device_data WHERE " +
                            "timestamp > NOW() - INTERVAL 1 HOUR";
            Long totalRecords = jdbcTemplate.queryForObject(totalSql, Long.class);

            return totalRecords > 0 ? (double) accurateRecords / totalRecords : 0.0;

        } catch (Exception e) {
            log.error("æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§å¤±è´¥", e);
            return 0.0;
        }
    }
}
```

---

## ğŸ“‹ å®æ–½å»ºè®®å’Œæœ€ä½³å®è·µ

### ğŸ¯ 1. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### æ•°æ®å¤„ç†ä¼˜åŒ–
- ä½¿ç”¨æ‰¹å¤„ç†å‡å°‘ç½‘ç»œå¼€é”€
- å®ç°æ•°æ®å‹ç¼©å‡å°‘å­˜å‚¨ç©ºé—´
- é‡‡ç”¨åˆ†åŒºè¡¨æé«˜æŸ¥è¯¢æ€§èƒ½
- ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—

#### å­˜å‚¨ä¼˜åŒ–
- åˆç†é€‰æ‹©å­˜å‚¨å¼•æ“ï¼ˆæ—¶åºæ•°æ®ã€åˆ†ææ•°æ®ã€æ–‡æ¡£æ•°æ®ï¼‰
- å®ç°æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
- é‡‡ç”¨æ•°æ®åˆ†å±‚å­˜å‚¨ç­–ç•¥
- å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®

### ğŸ”§ 2. å¯é æ€§ä¿éšœ

#### å®¹é”™æœºåˆ¶
- å®ç°æ•°æ®é‡è¯•æœºåˆ¶
- å»ºç«‹æ•…éšœè½¬ç§»ç­–ç•¥
- è®¾è®¡é™çº§å¤„ç†æ–¹æ¡ˆ
- å®Œå–„ç›‘æ§å‘Šè­¦ä½“ç³»

#### æ•°æ®ä¸€è‡´æ€§
- å®ç°äº‹åŠ¡å¤„ç†
- å»ºç«‹æ•°æ®æ ¡éªŒæœºåˆ¶
- è®¾è®¡æ•°æ®å›æ»šç­–ç•¥
- å®Œå–„å®¡è®¡æ—¥å¿—

### ğŸ“Š 3. æ‰©å±•æ€§è®¾è®¡

#### æ°´å¹³æ‰©å±•
- å¾®æœåŠ¡æ¶æ„è®¾è®¡
- æ•°æ®åˆ†ç‰‡ç­–ç•¥
- è´Ÿè½½å‡è¡¡é…ç½®
- å¼¹æ€§ä¼¸ç¼©æœºåˆ¶

#### å‚ç›´æ‰©å±•
- ç¡¬ä»¶èµ„æºä¼˜åŒ–
- ç®—æ³•æ€§èƒ½ä¼˜åŒ–
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- å¹¶å‘å¤„ç†ä¼˜åŒ–

---

**âš ï¸ é‡è¦æé†’**: æ•°æ®é‡‡é›†å’Œå¤„ç†æ¶æ„æ˜¯IOTå¹³å°çš„æ ¸å¿ƒï¼Œéœ€è¦ç»¼åˆè€ƒè™‘æ€§èƒ½ã€å¯é æ€§ã€æ‰©å±•æ€§å’Œæˆæœ¬ã€‚åœ¨å®æ–½è¿‡ç¨‹ä¸­éœ€è¦ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£çš„è®¾è®¡è§„èŒƒæ‰§è¡Œï¼Œå¹¶å»ºç«‹å®Œå–„çš„ç›‘æ§å’Œè¿ç»´ä½“ç³»ï¼Œç¡®ä¿æ•°æ®å¤„ç†çš„ç¨³å®šå’Œé«˜æ•ˆã€‚