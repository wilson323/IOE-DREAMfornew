#!/bin/bash

# =============================================================================
# IOE-DREAM è´¨é‡æ”¹è¿›é¢„æµ‹æ¨¡å‹
# åŠŸèƒ½ï¼šåŸºäºæœºå™¨å­¦ä¹ ç®—æ³•é¢„æµ‹ç¼–è¯‘é”™è¯¯ä¿®å¤è¶‹åŠ¿
# åˆ›å»ºæ—¶é—´ï¼š2025-11-18
# ç‰ˆæœ¬ï¼šv1.0.0
# =============================================================================

PROJECT_ROOT="D:\IOE-DREAM"
MONITORING_DIR="$PROJECT_ROOT/monitoring"
MODEL_DIR="$PROJECT_ROOT/models"
PREDICTIONS_FILE="$MONITORING_DIR/predictions.json"
HISTORY_FILE="$MONITORING_DIR/quality_history.json"

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p "$MODEL_DIR"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m'

echo -e "${CYAN}ğŸ¤– å¯åŠ¨è´¨é‡æ”¹è¿›é¢„æµ‹æ¨¡å‹...${NC}"

# 1. æ•°æ®æ”¶é›†å’Œé¢„å¤„ç†
collect_training_data() {
    echo -e "${BLUE}ğŸ“Š æ”¶é›†è®­ç»ƒæ•°æ®...${NC}"

    # è·å–å½“å‰ç¼–è¯‘é”™è¯¯è¯¦æƒ…
    cd "$PROJECT_ROOT/smart-admin-api-java17-springboot3"

    # æ‰§è¡Œç¼–è¯‘å¹¶æ”¶é›†æ•°æ®
    local start_time=$(date +%s)
    mvn compile -q 2>&1 > compile_output.log

    local end_time=$(date +%s)
    local compile_duration=$((end_time - start_time))

    # æå–é”™è¯¯æŒ‡æ ‡
    local total_errors=$(grep -c "ERROR" compile_output.log)
    local cannot_find_symbol=$(grep -c "cannot find symbol" compile_output.log)
    local package_not_found=$(grep -c "package.*does not exist" compile_output.log)
    local duplicate_method=$(grep -c "duplicate method" compile_output.log)
    local cannot_resolve=$(grep -c "cannot resolve" compile_output.log)
    local jakarta_issues=$(grep -c "javax\." compile_output.log)
    local autowired_issues=$(grep -c "@Autowired" compile_output.log)

    # è®¡ç®—é”™è¯¯å¯†åº¦
    local java_files_count=$(find . -name "*.java" | wc -l)
    local error_density=$(echo "scale=3; $total_errors / $java_files_count" | bc -l)

    # åˆ›å»ºè®­ç»ƒæ•°æ®ç‚¹
    cat <<EOF > training_data_point.json
{
  "timestamp": "$(date -Iseconds)",
  "compile_time": $compile_duration,
  "metrics": {
    "total_errors": $total_errors,
    "error_density": $error_density,
    "java_files_count": $java_files_count,
    "error_breakdown": {
      "cannot_find_symbol": $cannot_find_symbol,
      "package_not_found": $package_not_found,
      "duplicate_method": $duplicate_method,
      "cannot_resolve": $cannot_resolve,
      "jakarta_issues": $jakarta_issues,
      "autowired_issues": $autowired_issues
    }
  }
}
EOF

    # æ·»åŠ åˆ°å†å²æ•°æ®
    if [ ! -f "$HISTORY_FILE" ]; then
        echo "[]" > "$HISTORY_FILE"
    fi

    local temp_file=$(mktemp)
    jq ". + [$(cat training_data_point.json)]" "$HISTORY_FILE" > "$temp_file" && mv "$temp_file" "$HISTORY_FILE"

    rm -f training_data_point.json compile_output.log
    echo -e "${GREEN}âœ… è®­ç»ƒæ•°æ®æ”¶é›†å®Œæˆ${NC}"
}

# 2. ç‰¹å¾å·¥ç¨‹
feature_engineering() {
    echo -e "${BLUE}ğŸ”§ æ‰§è¡Œç‰¹å¾å·¥ç¨‹...${NC}"

    python3 << 'EOF' > "$MODEL_DIR/features.json"
import json
import numpy as np
from datetime import datetime, timedelta

# åŠ è½½å†å²æ•°æ®
with open("D:/IOE-DREAM/monitoring/quality_history.json", 'r', encoding='utf-8') as f:
    history_data = json.load(f)

if len(history_data) < 5:
    print(json.dumps({"status": "insufficient_data", "message": "éœ€è¦è‡³å°‘5ä¸ªæ•°æ®ç‚¹"}))
    exit()

# ç‰¹å¾æå–
features = []
labels = []

for i in range(1, len(history_data)):
    current = history_data[i]['metrics']
    previous = history_data[i-1]['metrics']

    # åŸºç¡€ç‰¹å¾
    total_errors = current['total_errors']
    error_density = current['error_density']

    # å˜åŒ–ç‡ç‰¹å¾
    error_change = current['total_errors'] - previous['total_errors']
    error_change_rate = error_change / max(previous['total_errors'], 1)

    # è¶‹åŠ¿ç‰¹å¾ï¼ˆæœ€è¿‘3ä¸ªç‚¹ï¼‰
    trend_data = []
    for j in range(max(0, i-2), i+1):
        trend_data.append(history_data[j]['metrics']['total_errors'])

    # è®¡ç®—è¶‹åŠ¿æ–œç‡
    if len(trend_data) >= 2:
        x = np.arange(len(trend_data))
        y = np.array(trend_data)
        trend_slope = np.polyfit(x, y, 1)[0]
    else:
        trend_slope = 0

    # é”™è¯¯ç±»å‹åˆ†å¸ƒç‰¹å¾
    breakdown = current['error_breakdown']
    jakarta_ratio = breakdown.get('jakarta_issues', 0) / max(total_errors, 1)
    autowired_ratio = breakdown.get('autowired_issues', 0) / max(total_errors, 1)
    symbol_ratio = breakdown.get('cannot_find_symbol', 0) / max(total_errors, 1)

    # ç¼–è¯‘æ—¶é—´ç‰¹å¾
    compile_time = history_data[i].get('compile_time', 0)

    feature_vector = {
        "total_errors": total_errors,
        "error_density": error_density,
        "error_change": error_change,
        "error_change_rate": error_change_rate,
        "trend_slope": trend_slope,
        "jakarta_ratio": jakarta_ratio,
        "autowired_ratio": autowired_ratio,
        "symbol_ratio": symbol_ratio,
        "compile_time": compile_time
    }

    features.append(feature_vector)
    # æ ‡ç­¾ï¼šä¸‹ä¸€æ—¶é—´ç‚¹çš„é”™è¯¯æ•°é‡å˜åŒ–
    if i < len(history_data) - 1:
        next_errors = history_data[i+1]['metrics']['total_errors']
        labels.append(next_errors - total_errors)

# ä¿å­˜ç‰¹å¾æ•°æ®
result = {
    "features": features,
    "labels": labels,
    "feature_count": len(features),
    "feature_names": list(features[0].keys()) if features else []
}

print(json.dumps(result, indent=2, ensure_ascii=False))
EOF

    echo -e "${GREEN}âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ${NC}"
}

# 3. é¢„æµ‹æ¨¡å‹è®­ç»ƒ
train_prediction_model() {
    echo -e "${BLUE}ğŸ¯ è®­ç»ƒé¢„æµ‹æ¨¡å‹...${NC}"

    python3 << 'EOF'
import json
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import pickle

# åŠ è½½ç‰¹å¾æ•°æ®
with open("D:/IOE-DREAM/models/features.json", 'r', encoding='utf-8') as f:
    data = json.load(f)

if data['feature_count'] < 10:
    print(json.dumps({"status": "insufficient_data", "message": "éœ€è¦è‡³å°‘10ä¸ªç‰¹å¾æ•°æ®ç‚¹"}))
    exit()

# å‡†å¤‡è®­ç»ƒæ•°æ®
features = np.array([[f[name] for name in data['feature_names']] for f in data['features']])
labels = np.array(data['labels'])

# åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# è®­ç»ƒå¤šä¸ªæ¨¡å‹
models = {}

# 1. çº¿æ€§å›å½’æ¨¡å‹
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)
lr_score = r2_score(y_test, lr_pred)
models['linear_regression'] = {
    'model': 'linear_regression',
    'r2_score': lr_score,
    'mse': mean_squared_error(y_test, lr_pred)
}

# 2. éšæœºæ£®æ—æ¨¡å‹
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_score = r2_score(y_test, rf_pred)
models['random_forest'] = {
    'model': 'random_forest',
    'r2_score': rf_score,
    'mse': mean_squared_error(y_test, rf_pred)
}

# é€‰æ‹©æœ€ä½³æ¨¡å‹
best_model_name = max(models.keys(), key=lambda k: models[k]['r2_score'])
best_model = rf_model if best_model_name == 'random_forest' else lr_model

# ä¿å­˜æœ€ä½³æ¨¡å‹
model_path = f"D:/IOE-DREAM/models/{best_model_name}_model.pkl"
with open(model_path, 'wb') as f:
    pickle.dump(best_model, f)

# ä¿å­˜æ¨¡å‹ä¿¡æ¯
model_info = {
    "best_model": best_model_name,
    "feature_names": data['feature_names'],
    "performance": models[best_model_name],
    "all_models": models,
    "training_samples": len(X_train),
    "test_samples": len(X_test)
}

with open("D:/IOE-DREAM/models/model_info.json", 'w', encoding='utf-8') as f:
    json.dump(model_info, f, indent=2, ensure_ascii=False)

print(json.dumps({"status": "success", "model_info": model_info}, ensure_ascii=False))
EOF

    echo -e "${GREEN}âœ… é¢„æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ${NC}"
}

# 4. ç”Ÿæˆé¢„æµ‹
make_predictions() {
    echo -e "${BLUE}ğŸ”® ç”Ÿæˆè´¨é‡æ”¹è¿›é¢„æµ‹...${NC}"

    python3 << 'EOF'
import json
import numpy as np
import pickle
from datetime import datetime, timedelta

# åŠ è½½æ¨¡å‹ä¿¡æ¯
try:
    with open("D:/IOE-DREAM/models/model_info.json", 'r', encoding='utf-8') as f:
        model_info = json.load(f)

    model_name = model_info['best_model']
    feature_names = model_info['feature_names']

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    with open(f"D:/IOE-DREAM/models/{model_name}_model.pkl", 'rb') as f:
        model = pickle.load(f)

except Exception as e:
    print(json.dumps({"status": "error", "message": f"æ— æ³•åŠ è½½æ¨¡å‹: {str(e)}"}))
    exit()

# è·å–æœ€æ–°ç‰¹å¾æ•°æ®
with open("D:/IOE-DREAM/models/features.json", 'r', encoding='utf-8') as f:
    features_data = json.load(f)

latest_features = features_data['features'][-1]
feature_vector = [latest_features[name] for name in feature_names]

# é¢„æµ‹æœªæ¥å¤šä¸ªæ—¶é—´ç‚¹
predictions = []
current_errors = latest_features['total_errors']

# é¢„æµ‹æœªæ¥20å°æ—¶çš„é”™è¯¯å˜åŒ–ï¼ˆå‡è®¾æ¯å°æ—¶ä¸€ä¸ªæ—¶é—´ç‚¹ï¼‰
for hours_ahead in range(1, 21):
    # æ¨¡æ‹Ÿç‰¹å¾å˜åŒ–ï¼ˆç®€åŒ–å‡è®¾ï¼‰
    future_features = feature_vector.copy()

    # åŸºäºå†å²è¶‹åŠ¿è°ƒæ•´ç‰¹å¾
    if 'trend_slope' in feature_names:
        trend_idx = feature_names.index('trend_slope')
        future_features[trend_idx] *= 1.05  # å‡è®¾è¶‹åŠ¿ç•¥æœ‰æ”¹å–„

    # è¿›è¡Œé¢„æµ‹
    predicted_change = model.predict([future_features])[0]
    predicted_errors = max(0, current_errors + predicted_change)

    predictions.append({
        "hours_ahead": hours_ahead,
        "predicted_errors": int(predicted_errors),
        "predicted_change": int(predicted_change),
        "confidence_interval": {
            "lower": max(0, int(predicted_errors - abs(predicted_change) * 0.5)),
            "upper": int(predicted_errors + abs(predicted_change) * 0.5)
        }
    })

    current_errors = predicted_errors

# åˆ†æé¢„æµ‹ç»“æœ
final_predicted = predictions[-1]['predicted_errors']
target_errors = 120
improvement_needed = latest_features['total_errors'] - target_errors
target_achievable = final_predicted <= target_errors

# è®¡ç®—è¾¾æˆæ¦‚ç‡
better_predictions = [p for p in predictions if p['predicted_errors'] <= target_errors]
achievement_probability = len(better_predictions) / len(predictions) * 100

# ç”Ÿæˆä¼˜åŒ–å»ºè®®
recommendations = []

if final_predicted > target_errors:
    if latest_features['jakarta_ratio'] > 0.1:
        recommendations.append({
            "action": "æ‰¹é‡ä¿®å¤JakartaåŒ…åé—®é¢˜",
            "expected_reduction": int(latest_features['total_errors'] * latest_features['jakarta_ratio']),
            "priority": "high"
        })

    if latest_features['autowired_ratio'] > 0.05:
        recommendations.append({
            "action": "æ›¿æ¢@Autowiredæ³¨è§£ä¸º@Resource",
            "expected_reduction": int(latest_features['total_errors'] * latest_features['autowired_ratio']),
            "priority": "high"
        })

    if latest_features['symbol_ratio'] > 0.5:
        recommendations.append({
            "action": "è¡¥å……ç¼ºå¤±çš„ç±»å’Œç¬¦å·å®šä¹‰",
            "expected_reduction": int(latest_features['total_errors'] * 0.3),
            "priority": "medium"
        })

prediction_result = {
    "timestamp": datetime.now().isoformat(),
    "current_errors": latest_features['total_errors'],
    "target_errors": target_errors,
    "final_predicted_errors": final_predicted,
    "improvement_needed": improvement_needed,
    "target_achievable": target_achievable,
    "achievement_probability": round(achievement_probability, 1),
    "model_used": model_name,
    "model_confidence": round(model_info['performance']['r2_score'] * 100, 1),
    "predictions": predictions,
    "recommendations": recommendations,
    "key_insights": {
        "error_density": latest_features['error_density'],
        "trend_direction": "decreasing" if latest_features.get('trend_slope', 0) < 0 else "increasing",
        "primary_error_type": max([
            ("jakarta", latest_features.get('jakarta_ratio', 0)),
            ("autowired", latest_features.get('autowired_ratio', 0)),
            ("symbol", latest_features.get('symbol_ratio', 0))
        ], key=lambda x: x[1])[0]
    }
}

# ä¿å­˜é¢„æµ‹ç»“æœ
with open("D:/IOE-DREAM/monitoring/predictions.json", 'w', encoding='utf-8') as f:
    json.dump(prediction_result, f, indent=2, ensure_ascii=False)

print(json.dumps({"status": "success", "predictions": prediction_result}, ensure_ascii=False))
EOF

    echo -e "${GREEN}âœ… é¢„æµ‹ç”Ÿæˆå®Œæˆ${NC}"
}

# 5. æ˜¾ç¤ºé¢„æµ‹æŠ¥å‘Š
show_prediction_report() {
    if [ ! -f "$PREDICTIONS_FILE" ]; then
        echo -e "${RED}âŒ é¢„æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œé¢„æµ‹${NC}"
        return
    fi

    echo -e "\n${CYAN}========================================${NC}"
    echo -e "${WHITE}ğŸ”® è´¨é‡æ”¹è¿›é¢„æµ‹æŠ¥å‘Š${NC}"
    echo -e "${CYAN}========================================${NC}\n"

    # è¯»å–é¢„æµ‹ç»“æœ
    local current_errors=$(jq -r '.current_errors' "$PREDICTIONS_FILE")
    local target_errors=$(jq -r '.target_errors' "$PREDICTIONS_FILE")
    local final_predicted=$(jq -r '.final_predicted_errors' "$PREDICTIONS_FILE")
    local achievement_prob=$(jq -r '.achievement_probability' "$PREDICTIONS_FILE")
    local model_confidence=$(jq -r '.model_confidence' "$PREDICTIONS_FILE")
    local model_used=$(jq -r '.model_used' "$PREDICTIONS_FILE")
    local target_achievable=$(jq -r '.target_achievable' "$PREDICTIONS_FILE")

    # å½“å‰çŠ¶æ€
    echo -e "${BLUE}ğŸ“Š å½“å‰çŠ¶æ€${NC}"
    echo -e "å½“å‰é”™è¯¯æ•°: ${RED}$current_errors${NC}"
    echo -e "ç›®æ ‡é”™è¯¯æ•°: ${GREEN}$target_errors${NC}"
    echo -e "éœ€è¦æ”¹è¿›: ${RED}$((current_errors - target_errors))${NC} ä¸ªé”™è¯¯"
    echo ""

    # é¢„æµ‹ç»“æœ
    echo -e "${PURPLE}ğŸ¯ 20å°æ—¶åé¢„æµ‹${NC}"
    echo -e "é¢„æµ‹é”™è¯¯æ•°: ${WHITE}$final_predicted${NC}"

    if [ "$target_achievable" = "true" ]; then
        echo -e "ç›®æ ‡è¾¾æˆ: ${GREEN}âœ… å¯ä»¥è¾¾æˆ${NC}"
    else
        echo -e "ç›®æ ‡è¾¾æˆ: ${RED}âŒ æ— æ³•è¾¾æˆ${NC}"
    fi

    echo -e "è¾¾æˆæ¦‚ç‡: ${WHITE}$achievement_prob%${NC}"
    echo -e "æ¨¡å‹ç½®ä¿¡åº¦: ${WHITE}$model_confidence%${NC}"
    echo -e "ä½¿ç”¨æ¨¡å‹: ${WHITE}$model_used${NC}"
    echo ""

    # å…³é”®æ´å¯Ÿ
    echo -e "${BLUE}ğŸ” å…³é”®æ´å¯Ÿ${NC}"
    local error_density=$(jq -r '.key_insights.error_density' "$PREDICTIONS_FILE")
    local trend_direction=$(jq -r '.key_insights.trend_direction' "$PREDICTIONS_FILE")
    local primary_error_type=$(jq -r '.key_insights.primary_error_type' "$PREDICTIONS_FILE")

    echo -e "é”™è¯¯å¯†åº¦: ${WHITE}$error_density${NC} é”™è¯¯/æ–‡ä»¶"

    if [ "$trend_direction" = "decreasing" ]; then
        echo -e "é”™è¯¯è¶‹åŠ¿: ${GREEN}ğŸ“‰ ä¸‹é™ä¸­${NC}"
    else
        echo -e "é”™è¯¯è¶‹åŠ¿: ${RED}ğŸ“ˆ ä¸Šå‡ä¸­${NC}"
    fi

    echo -e "ä¸»è¦é”™è¯¯ç±»å‹: ${WHITE}$primary_error_type${NC}"
    echo ""

    # ä¼˜åŒ–å»ºè®®
    echo -e "${YELLOW}ğŸ’¡ ä¼˜åŒ–å»ºè®®${NC}"
    jq -r '.recommendations[] | "â€¢ \(.action) (é¢„è®¡å‡å°‘: \(.expected_reduction)ä¸ªé”™è¯¯, ä¼˜å…ˆçº§: \(.priority))"' "$PREDICTIONS_FILE"
    echo ""

    # æ—¶é—´è½´é¢„æµ‹
    echo -e "${BLUE}ğŸ“ˆ æ—¶é—´è½´é¢„æµ‹ (å…³é”®æ—¶é—´ç‚¹)${NC}"
    echo "å½“å‰ â†’ 6å°æ—¶ â†’ 12å°æ—¶ â†’ 20å°æ—¶"

    # æå–å…³é”®é¢„æµ‹ç‚¹
    local prediction_6h=$(jq -r '.predictions[5].predicted_errors // "N/A"' "$PREDICTIONS_FILE")
    local prediction_12h=$(jq -r '.predictions[11].predicted_errors // "N/A"' "$PREDICTIONS_FILE")
    local prediction_20h=$(jq -r '.predictions[19].predicted_errors // "N/A"' "$PREDICTIONS_FILE")

    echo -e "é”™è¯¯æ•°: $current_errors â†’ $prediction_6h â†’ $prediction_12h â†’ $prediction_20h"

    # ç›®æ ‡çº¿
    echo -e "ç›®æ ‡çº¿: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ $target_errors (ç›®æ ‡çº¿)"
}

# 6. é£é™©è¯„ä¼°
assess_risks() {
    if [ ! -f "$PREDICTIONS_FILE" ]; then
        return
    fi

    echo -e "\n${YELLOW}âš ï¸ é£é™©è¯„ä¼°${NC}"

    local achievement_prob=$(jq -r '.achievement_probability' "$PREDICTIONS_FILE")
    local current_errors=$(jq -r '.current_errors' "$PREDICTIONS_FILE")

    if [ "$achievement_prob" -lt 30 ]; then
        echo -e "é£é™©ç­‰çº§: ${RED}ğŸ”´ é«˜é£é™©${NC}"
        echo -e "å»ºè®®æªæ–½:"
        echo -e "â€¢ å¢åŠ å¼€å‘äººå‘˜åˆ°2-3äºº"
        echo -e "â€¢ ä¼˜å…ˆæ‰¹é‡ä¿®å¤è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜çš„é—®é¢˜"
        echo -e "â€¢ è€ƒè™‘é™ä½ç›®æ ‡æ ‡å‡†æˆ–å»¶é•¿æ—¶é—´çª—å£"
    elif [ "$achievement_prob" -lt 70 ]; then
        echo -e "é£é™©ç­‰çº§: ${YELLOW}ğŸŸ¡ ä¸­ç­‰é£é™©${NC}"
        echo -e "å»ºè®®æªæ–½:"
        echo -e "â€¢ åŠ å¼ºå¼€å‘æ•ˆç‡ç›‘æ§"
        echo -e "â€¢ é‡ç‚¹è§£å†³ä¸»è¦é”™è¯¯ç±»å‹"
        echo -e "â€¢ å‡†å¤‡å¤‡ç”¨ä¿®å¤ç­–ç•¥"
    else
        echo -e "é£é™©ç­‰çº§: ${GREEN}ğŸŸ¢ ä½é£é™©${NC}"
        echo -e "å»ºè®®æªæ–½:"
        echo -e "â€¢ ä¿æŒå½“å‰ä¿®å¤èŠ‚å¥"
        echo -e "â€¢ å…³æ³¨ä»£ç è´¨é‡"
        echo -e "â€¢ å‡†å¤‡æœ€ç»ˆéªŒæ”¶æµ‹è¯•"
    fi
}

# ä¸»ç¨‹åº
main() {
    local action="${1:-predict}"

    case "$action" in
        "collect")
            collect_training_data
            ;;
        "features")
            feature_engineering
            ;;
        "train")
            train_prediction_model
            ;;
        "predict"|"")
            collect_training_data
            feature_engineering
            train_prediction_model
            make_predictions
            show_prediction_report
            assess_risks
            ;;
        "report")
            show_prediction_report
            assess_risks
            ;;
        *)
            echo "ç”¨æ³•: $0 [collect|features|train|predict|report]"
            exit 1
            ;;
    esac
}

# æ£€æŸ¥Pythonä¾èµ–
if ! python3 -c "import sklearn, numpy, pickle" 2>/dev/null; then
    echo -e "${RED}âŒ éœ€è¦å®‰è£…æœºå™¨å­¦ä¹ ä¾èµ–: pip install scikit-learn numpy${NC}"
    exit 1
fi

# æ‰§è¡Œä¸»ç¨‹åº
main "$@"

echo -e "\n${GREEN}ğŸ‰ è´¨é‡æ”¹è¿›é¢„æµ‹å®Œæˆï¼${NC}"