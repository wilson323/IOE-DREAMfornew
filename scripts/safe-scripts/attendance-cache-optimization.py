#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è€ƒå‹¤æ¨¡å—ç¼“å­˜ä¼˜åŒ–å®ç°
æ”¯æŒRedisç¼“å­˜ã€å¤šçº§ç¼“å­˜ç­–ç•¥å’Œæ™ºèƒ½ç¼“å­˜å¤±æ•ˆ
"""

import json
import redis
import hashlib
import logging
from typing import Any, Optional, Dict, List, Union
from datetime import datetime, timedelta
import threading
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AttendanceCacheManager:
    """è€ƒå‹¤æ¨¡å—ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, host='localhost', port=6379, db=1, password=None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            host: Redisä¸»æœºåœ°å€
            port: Redisç«¯å£
            db: æ•°æ®åº“ç¼–å·
            password: å¯†ç 
        """
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=True
        )

        # å†…å­˜ç¼“å­˜ï¼ˆäºŒçº§ç¼“å­˜ï¼‰
        self.memory_cache = {}
        self.memory_cache_lock = threading.Lock()

        # ç¼“å­˜é…ç½®
        self.cache_config = {
            'default_ttl': 3600,  # é»˜è®¤1å°æ—¶
            'short_ttl': 300,     # çŸ­æœŸç¼“å­˜5åˆ†é’Ÿ
            'long_ttl': 86400,     # é•¿æœŸç¼“å­˜24å°æ—¶

            # å„ç§æ•°æ®çš„TTLé…ç½®
            'attendance_record': 1800,      # æ‰“å¡è®°å½•ç¼“å­˜30åˆ†é’Ÿ
            'employee_schedule': 3600,       # å‘˜å·¥æ’ç­ç¼“å­˜1å°æ—¶
            'attendance_statistics': 7200,  # è€ƒå‹¤ç»Ÿè®¡ç¼“å­˜2å°æ—¶
            'department_stats': 3600,        # éƒ¨é—¨ç»Ÿè®¡ç¼“å­˜1å°æ—¶
            'attendance_rules': 86400,       # è€ƒå‹¤è§„åˆ™ç¼“å­˜24å°æ—¶
            'today_attendance': 300,         # ä»Šæ—¥è€ƒå‹¤ç¼“å­˜5åˆ†é’Ÿ
            'calendar_data': 1800,            # æ—¥å†æ•°æ®ç¼“å­˜30åˆ†é’Ÿ
        }

        # ç¼“å­˜é”®å‰ç¼€
        self.key_prefix = 'attendance:'

        logger.info("è€ƒå‹¤ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _generate_cache_key(self, key: str, prefix: str = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        if prefix:
            return f"{self.key_prefix}{prefix}:{key}"
        return f"{self.key_prefix}{key}"

    def _get_ttl(self, cache_type: str) -> int:
        """è·å–TTL"""
        return self.cache_config.get(cache_type, self.cache_config['default_ttl'])

    def set(self, key: str, value: Any, ttl: int = None, cache_type: str = None) -> bool:
        """
        è®¾ç½®ç¼“å­˜

        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            cache_type: ç¼“å­˜ç±»å‹

        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            if ttl is None and cache_type:
                ttl = self._get_ttl(cache_type)
            elif ttl is None:
                ttl = self.cache_config['default_ttl']

            cache_key = self._generate_cache_key(key)

            # åºåˆ—åŒ–å€¼
            if not isinstance(value, str):
                if isinstance(value, (dict, list)):
                    value = json.dumps(value, ensure_ascii=False)
                else:
                    value = str(value)

            # è®¾ç½®Redisç¼“å­˜
            redis_result = self.redis_client.setex(cache_key, ttl, value)

            # è®¾ç½®å†…å­˜ç¼“å­˜
            with self.memory_cache_lock:
                self.memory_cache[cache_key] = {
                    'value': value,
                    'expire_time': time.time() + ttl
                }

            return redis_result

        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜å¤±è´¥: {e}")
            return False

    def get(self, key: str, cache_type: str = None) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            cache_type: ç¼“å­˜ç±»å‹

        Returns:
            Any: ç¼“å­˜å€¼ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            cache_key = self._generate_cache_key(key)

            # å…ˆæŸ¥å†…å­˜ç¼“å­˜
            with self.memory_cache_lock:
                if cache_key in self.memory_cache:
                    cache_item = self.memory_cache[cache_key]
                    if cache_item['expire_time'] > time.time():
                        return self._deserialize_value(cache_item['value'])
                    else:
                        # å†…å­˜ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                        del self.memory_cache[cache_key]

            # æŸ¥Redisç¼“å­˜
            value = self.redis_client.get(cache_key)
            if value is not None:
                # åŒæ­¥åˆ°å†…å­˜ç¼“å­˜
                ttl = self._get_ttl(cache_type) if cache_type else self.cache_config['default_ttl']
                with self.memory_cache_lock:
                    self.memory_cache[cache_key] = {
                        'value': value,
                        'expire_time': time.time() + ttl
                    }

                return self._deserialize_value(value)

            return None

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜å¤±è´¥: {e}")
            return None

    def _deserialize_value(self, value: str) -> Any:
        """ååºåˆ—åŒ–å€¼"""
        try:
            # å°è¯•è§£æJSON
            return json.loads(value)
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœä¸æ˜¯JSONï¼Œè¿”å›åŸå€¼
            return value

    def delete(self, key: str) -> bool:
        """
        åˆ é™¤ç¼“å­˜

        Args:
            key: ç¼“å­˜é”®

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            cache_key = self._generate_cache_key(key)

            # åˆ é™¤Redisç¼“å­˜
            redis_result = self.redis_client.delete(cache_key)

            # åˆ é™¤å†…å­˜ç¼“å­˜
            with self.memory_cache_lock:
                if cache_key in self.memory_cache:
                    del self.memory_cache[cache_key]

            return redis_result

        except Exception as e:
            logger.error(f"åˆ é™¤ç¼“å­˜å¤±è´¥: {e}")
            return False

    def clear_pattern(self, pattern: str) -> int:
        """
        æ‰¹é‡åˆ é™¤ç¼“å­˜

        Args:
            pattern: åŒ¹é…æ¨¡å¼

        Returns:
            int: åˆ é™¤çš„é”®æ•°é‡
        """
        try:
            cache_pattern = self._generate_cache_key(pattern)
            keys = self.redis_client.keys(cache_pattern)

            if keys:
                deleted_count = self.redis_client.delete(*keys)

                # æ¸…ç†å†…å­˜ç¼“å­˜
                with self.memory_cache_lock:
                    keys_to_delete = [k for k in self.memory_cache.keys() if any(key in k for key in keys)]
                    for k in keys_to_delete:
                        del self.memory_cache[k]

                return deleted_count

            return 0

        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ é™¤ç¼“å­˜å¤±è´¥: {e}")
            return 0

    def exists(self, key: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨

        Args:
            key: ç¼“å­˜é”®

        Returns:
            bool: æ˜¯å¦å­˜åœ¨
        """
        try:
            cache_key = self._generate_cache_key(key)

            # å…ˆæŸ¥å†…å­˜ç¼“å­˜
            with self.memory_cache_lock:
                if cache_key in self.memory_cache:
                    cache_item = self.memory_cache[cache_key]
                    return cache_item['expire_time'] > time.time()

            # æŸ¥Redisç¼“å­˜
            return self.redis_client.exists(cache_key) > 0

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç¼“å­˜å­˜åœ¨æ€§å¤±è´¥: {e}")
            return False

    def expire(self, key: str, ttl: int) -> bool:
        """
        è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´

        Args:
            key: ç¼“å­˜é”®
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            cache_key = self._generate_cache_key(key)

            # è®¾ç½®Redisè¿‡æœŸæ—¶é—´
            redis_result = self.redis_client.expire(cache_key, ttl)

            # æ›´æ–°å†…å­˜ç¼“å­˜è¿‡æœŸæ—¶é—´
            with self.memory_cache_lock:
                if cache_key in self.memory_cache:
                    self.memory_cache[cache_key]['expire_time'] = time.time() + ttl

            return redis_result

        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´å¤±è´¥: {e}")
            return False

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            redis_info = self.redis_client.info()

            with self.memory_cache_lock:
                memory_cache_size = len(self.memory_cache)

            return {
                'redis_memory_used': redis_info.get('used_memory_human'),
                'redis_connected_clients': redis_info.get('connected_clients'),
                'redis_keyspace_hits': redis_info.get('keyspace_hits', 0),
                'redis_keyspace_misses': redis_info.get('keyspace_misses', 0),
                'memory_cache_size': memory_cache_size,
                'hit_rate': self._calculate_hit_rate(redis_info)
            }

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {}

    def _calculate_hit_rate(self, redis_info: Dict) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        hits = redis_info.get('keyspace_hits', 0)
        misses = redis_info.get('keyspace_misses', 0)
        total = hits + misses

        if total > 0:
            return (hits / total) * 100
        return 0.0


class AttendanceCacheService:
    """è€ƒå‹¤ä¸šåŠ¡ç¼“å­˜æœåŠ¡"""

    def __init__(self, cache_manager: AttendanceCacheManager = None):
        """
        åˆå§‹åŒ–ç¼“å­˜æœåŠ¡

        Args:
            cache_manager: ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
        """
        self.cache_manager = cache_manager or AttendanceCacheManager()

        # ç¼“å­˜é”®æ¨¡å¼
        self.key_patterns = {
            'attendance_record': 'record:{employee_id}:{date}',
            'employee_schedule': 'schedule:{employee_id}',
            'attendance_statistics': 'stats:{type}:{params_hash}',
            'department_stats': 'dept_stats:{dept_id}:{date_range}',
            'today_attendance': 'today:{date}',
            'attendance_rules': 'rules:{employee_id}',
            'calendar_data': 'calendar:{year}:{month}'
        }

    def cache_attendance_record(self, employee_id: int, date: str, record_data: Dict) -> bool:
        """ç¼“å­˜è€ƒå‹¤è®°å½•"""
        key = self.key_patterns['attendance_record'].format(
            employee_id=employee_id,
            date=date
        )
        return self.cache_manager.set(key, record_data, cache_type='attendance_record')

    def get_attendance_record(self, employee_id: int, date: str) -> Optional[Dict]:
        """è·å–è€ƒå‹¤è®°å½•ç¼“å­˜"""
        key = self.key_patterns['attendance_record'].format(
            employee_id=employee_id,
            date=date
        )
        return self.cache_manager.get(key, 'attendance_record')

    def cache_employee_schedule(self, employee_id: int, schedule_data: List[Dict]) -> bool:
        """ç¼“å­˜å‘˜å·¥æ’ç­"""
        key = self.key_patterns['employee_schedule'].format(employee_id=employee_id)
        return self.cache_manager.set(key, schedule_data, cache_type='employee_schedule')

    def get_employee_schedule(self, employee_id: int) -> Optional[List[Dict]]:
        """è·å–å‘˜å·¥æ’ç­ç¼“å­˜"""
        key = self.key_patterns['employee_schedule'].format(employee_id=employee_id)
        return self.cache_manager.get(key, 'employee_schedule')

    def cache_attendance_statistics(self, stats_type: str, params: Dict, stats_data: Dict) -> bool:
        """ç¼“å­˜è€ƒå‹¤ç»Ÿè®¡æ•°æ®"""
        # ç”Ÿæˆå‚æ•°å“ˆå¸Œä½œä¸ºé”®çš„ä¸€éƒ¨åˆ†
        params_str = json.dumps(params, sort_keys=True)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()

        key = self.key_patterns['attendance_statistics'].format(
            type=stats_type,
            params_hash=params_hash
        )
        return self.cache_manager.set(key, stats_data, cache_type='attendance_statistics')

    def get_attendance_statistics(self, stats_type: str, params: Dict) -> Optional[Dict]:
        """è·å–è€ƒå‹¤ç»Ÿè®¡æ•°æ®ç¼“å­˜"""
        params_str = json.dumps(params, sort_keys=True)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()

        key = self.key_patterns['attendance_statistics'].format(
            type=stats_type,
            params_hash=params_hash
        )
        return self.cache_manager.get(key, 'attendance_statistics')

    def cache_department_stats(self, dept_id: int, date_range: str, stats_data: Dict) -> bool:
        """ç¼“å­˜éƒ¨é—¨ç»Ÿè®¡æ•°æ®"""
        key = self.key_patterns['department_stats'].format(
            dept_id=dept_id,
            date_range=date_range
        )
        return self.cache_manager.set(key, stats_data, cache_type='department_stats')

    def get_department_stats(self, dept_id: int, date_range: str) -> Optional[Dict]:
        """è·å–éƒ¨é—¨ç»Ÿè®¡æ•°æ®ç¼“å­˜"""
        key = self.key_patterns['department_stats'].format(
            dept_id=dept_id,
            date_range=date_range
        )
        return self.cache_manager.get(key, 'department_stats')

    def cache_today_attendance(self, date: str, attendance_data: Dict) -> bool:
        """ç¼“å­˜ä»Šæ—¥è€ƒå‹¤æ•°æ®"""
        key = self.key_patterns['today_attendance'].format(date=date)
        return self.cache_manager.set(key, attendance_data, cache_type='today_attendance')

    def get_today_attendance(self, date: str) -> Optional[Dict]:
        """è·å–ä»Šæ—¥è€ƒå‹¤æ•°æ®ç¼“å­˜"""
        key = self.key_patterns['today_attendance'].format(date=date)
        return self.cache_manager.get(key, 'today_attendance')

    def cache_attendance_rules(self, employee_id: int, rules_data: List[Dict]) -> bool:
        """ç¼“å­˜è€ƒå‹¤è§„åˆ™"""
        key = self.key_patterns['attendance_rules'].format(employee_id=employee_id)
        return self.cache_manager.set(key, rules_data, cache_type='attendance_rules')

    def get_attendance_rules(self, employee_id: int) -> Optional[List[Dict]]:
        """è·å–è€ƒå‹¤è§„åˆ™ç¼“å­˜"""
        key = self.key_patterns['attendance_rules'].format(employee_id=employee_id)
        return self.cache_manager.get(key, 'attendance_rules')

    def cache_calendar_data(self, year: int, month: int, calendar_data: List[Dict]) -> bool:
        """ç¼“å­˜æ—¥å†æ•°æ®"""
        key = self.key_patterns['calendar_data'].format(year=year, month=month)
        return self.cache_manager.set(key, calendar_data, cache_type='calendar_data')

    def get_calendar_data(self, year: int, month: int) -> Optional[List[Dict]]:
        """è·å–æ—¥å†æ•°æ®ç¼“å­˜"""
        key = self.key_patterns['calendar_data'].format(year=year, month=month)
        return self.cache_manager.get(key, 'calendar_data')

    def invalidate_employee_cache(self, employee_id: int) -> int:
        """å¤±æ•ˆå‘˜å·¥ç›¸å…³ç¼“å­˜"""
        patterns_to_clear = [
            f"record:{employee_id}:*",
            f"schedule:{employee_id}",
            f"rules:{employee_id}"
        ]

        cleared_count = 0
        for pattern in patterns_to_clear:
            cleared_count += self.cache_manager.clear_pattern(pattern)

        return cleared_count

    def invalidate_date_range_cache(self, start_date: str, end_date: str) -> int:
        """å¤±æ•ˆæ—¥æœŸèŒƒå›´ç›¸å…³ç¼“å­˜"""
        # æ¸…ç†ä»Šæ—¥è€ƒå‹¤ç¼“å­˜
        if start_date <= datetime.now().strftime('%Y-%m-%d') <= end_date:
            self.cache_manager.delete('today:' + datetime.now().strftime('%Y-%m-%d'))

        # æ¸…ç†ç»Ÿè®¡ç¼“å­˜ï¼ˆç”±äºå‚æ•°å¤æ‚ï¼Œç›´æ¥æ¸…ç©ºæ‰€æœ‰ç»Ÿè®¡ç¼“å­˜ï¼‰
        cleared_count = self.cache_manager.clear_pattern('stats:*')

        return cleared_count

    def warm_up_cache(self) -> Dict[str, int]:
        """ç¼“å­˜é¢„çƒ­

        Returns:
            Dict: é¢„çƒ­ç»“æœç»Ÿè®¡
        """
        results = {
            'success_count': 0,
            'error_count': 0,
            'total_count': 0
        }

        try:
            # é¢„çƒ­è€ƒå‹¤è§„åˆ™ç¼“å­˜
            # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“åŠ è½½å¸¸ç”¨æ•°æ®å¹¶ç¼“å­˜
            logger.info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")

            # ç¤ºä¾‹ï¼šé¢„çƒ­è€ƒå‹¤è§„åˆ™
            rules_data = [
                {
                    'rule_id': 1,
                    'rule_name': 'æ ‡å‡†å·¥ä½œåˆ¶',
                    'work_start_time': '09:00',
                    'work_end_time': '18:00'
                }
            ]

            if self.cache_manager.set('rules:warmup', rules_data, cache_type='attendance_rules'):
                results['success_count'] += 1
            else:
                results['error_count'] += 1

            results['total_count'] += 1

            logger.info(f"ç¼“å­˜é¢„çƒ­å®Œæˆ: æˆåŠŸ{results['success_count']}, å¤±è´¥{results['error_count']}")

        except Exception as e:
            logger.error(f"ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
            results['error_count'] += 1
            results['total_count'] += 1

        return results


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç¼“å­˜åŠŸèƒ½"""
    print("ğŸš€ è€ƒå‹¤æ¨¡å—ç¼“å­˜ä¼˜åŒ–æ¼”ç¤º")

    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = AttendanceCacheManager()
    cache_service = AttendanceCacheService(cache_manager)

    # æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ
    print("\nğŸ“ æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ...")

    # è®¾ç½®ç¼“å­˜
    test_data = {
        'employee_id': 1,
        'employee_name': 'å¼ ä¸‰',
        'punch_time': '2025-11-17 09:00:00',
        'punch_type': 'ä¸Šç­'
    }

    if cache_service.cache_attendance_record(1, '2025-11-17', test_data):
        print("âœ… ç¼“å­˜è®¾ç½®æˆåŠŸ")
    else:
        print("âŒ ç¼“å­˜è®¾ç½®å¤±è´¥")

    # è·å–ç¼“å­˜
    cached_data = cache_service.get_attendance_record(1, '2025-11-17')
    if cached_data:
        print(f"âœ… ç¼“å­˜è·å–æˆåŠŸ: {cached_data['employee_name']}")
    else:
        print("âŒ ç¼“å­˜è·å–å¤±è´¥")

    # æ¼”ç¤ºæ‰¹é‡æ“ä½œ
    print("\nğŸ“Š æ¼”ç¤ºæ‰¹é‡ç¼“å­˜æ“ä½œ...")

    # æ‰¹é‡è®¾ç½®å‘˜å·¥æ’ç­
    schedule_data = [
        {
            'date': '2025-11-18',
            'schedule_type': 'FIXED',
            'work_start_time': '09:00',
            'work_end_time': '18:00'
        },
        {
            'date': '2025-11-19',
            'schedule_type': 'FLEXIBLE',
            'work_start_time': '10:00',
            'work_end_time': '19:00'
        }
    ]

    if cache_service.cache_employee_schedule(1, schedule_data):
        print("âœ… æ‰¹é‡æ’ç­ç¼“å­˜è®¾ç½®æˆåŠŸ")
        print(f"   ç¼“å­˜äº† {len(schedule_data)} æ¡æ’ç­è®°å½•")
    else:
        print("âŒ æ‰¹é‡æ’ç­ç¼“å­˜è®¾ç½®å¤±è´¥")

    # æ¼”ç¤ºç¼“å­˜å¤±æ•ˆ
    print("\nğŸ—‘ï¸  æ¼”ç¤ºç¼“å­˜å¤±æ•ˆ...")

    invalidated_count = cache_service.invalidate_employee_cache(1)
    print(f"âœ… å¤±æ•ˆå‘˜å·¥ç¼“å­˜: {invalidated_count} ä¸ª")

    # è·å–ç¼“å­˜ç»Ÿè®¡
    print("\nğŸ“ˆ ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
    stats = cache_manager.get_cache_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")

    # æ¼”ç¤ºç¼“å­˜é¢„çƒ­
    print("\nğŸ”¥ æ¼”ç¤ºç¼“å­˜é¢„çƒ­...")
    warmup_results = cache_service.warm_up_cache()
    print(f"é¢„çƒ­ç»“æœ: {warmup_results}")

    print("\nğŸ‰ ç¼“å­˜ä¼˜åŒ–æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()