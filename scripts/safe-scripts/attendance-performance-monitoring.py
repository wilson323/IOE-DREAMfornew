#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è€ƒå‹¤æ¨¡å—æ€§èƒ½ç›‘æ§è„šæœ¬
å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ã€ç¼“å­˜å‘½ä¸­ç‡ã€APIå“åº”æ—¶é—´ç­‰
"""

import json
import redis
import logging
import time
import psutil
import pymysql
from datetime import datetime, timedelta
from typing import Dict, List, Any
import threading
import subprocess
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('attendance-performance-monitoring.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AttendancePerformanceMonitor:
    """è€ƒå‹¤æ¨¡å—æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, db_config: Dict[str, Any], redis_config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨

        Args:
            db_config: æ•°æ®åº“é…ç½®
            redis_config: Redisé…ç½®
        """
        self.db_config = db_config
        self.redis_config = redis_config
        self.monitoring_data = {
            'timestamp': [],
            'cpu_percent': [],
            'memory_percent': [],
            'db_query_time': [],
            'redis_hit_rate': [],
            'api_response_time': [],
            'active_connections': []
        }

        # è¿æ¥æ•°æ®åº“
        try:
            self.db_connection = pymysql.connect(
                host=db_config['host'],
                port=db_config['port'],
                user=db_config['user'],
                password=db_config['password'],
                database=db_config['database'],
                charset='utf8mb4'
            )
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            self.db_connection = None

        # è¿æ¥Redis
        try:
            self.redis_client = redis.Redis(
                host=redis_config['host'],
                port=redis_config['port'],
                db=redis_config['db'],
                password=redis_config['password'],
                decode_responses=True
            )
            self.redis_client.ping()
            logger.info("Redisè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"Redisè¿æ¥å¤±è´¥: {e}")
            self.redis_client = None

        # APIç›‘æ§é…ç½®
        self.api_endpoints = [
            'http://localhost:1024/api/attendance/today-punch',
            'http://localhost:1024/api/attendance/records',
            'http://localhost:1024/api/attendance/statistics',
            'http://localhost:1024/api/attendance/schedule'
        ]

    def monitor_system_resources(self) -> Dict[str, float]:
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100

            return {
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                'disk_percent': disk_percent
            }
        except Exception as e:
            logger.error(f"ç³»ç»Ÿèµ„æºç›‘æ§å¤±è´¥: {e}")
            return {
                'cpu_percent': 0,
                'memory_percent': 0,
                'disk_percent': 0
            }

    def monitor_database_performance(self) -> Dict[str, Any]:
        """ç›‘æ§æ•°æ®åº“æ€§èƒ½"""
        if not self.db_connection:
            return {'query_time': 0, 'active_connections': 0}

        try:
            cursor = self.db_connection.cursor()

            # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
            start_time = time.time()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            query_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            # è·å–æ´»è·ƒè¿æ¥æ•°
            cursor.execute("SHOW STATUS LIKE 'Threads_connected'")
            result = cursor.fetchone()
            active_connections = int(result[1]) if result else 0

            cursor.close()

            return {
                'query_time': query_time,
                'active_connections': active_connections
            }
        except Exception as e:
            logger.error(f"æ•°æ®åº“æ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
            return {
                'query_time': 0,
                'active_connections': 0
            }

    def monitor_redis_performance(self) -> Dict[str, Any]:
        """ç›‘æ§Redisæ€§èƒ½"""
        if not self.redis_client:
            return {'hit_rate': 0, 'memory_used': 0}

        try:
            info = self.redis_client.info()

            # è®¡ç®—å‘½ä¸­ç‡
            hits = info.get('keyspace_hits', 0)
            misses = info.get('keyspace_misses', 0)
            total = hits + misses
            hit_rate = (hits / total * 100) if total > 0 else 0

            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory_used = info.get('used_memory_human', '0M')

            return {
                'hit_rate': hit_rate,
                'memory_used': memory_used
            }
        except Exception as e:
            logger.error(f"Redisæ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
            return {
                'hit_rate': 0,
                'memory_used': 0
            }

    def monitor_api_performance(self) -> Dict[str, float]:
        """ç›‘æ§APIæ€§èƒ½"""
        response_times = []

        for endpoint in self.api_endpoints:
            try:
                start_time = time.time()
                response = requests.get(endpoint, timeout=5)
                response_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                response_times.append(response_time)
            except Exception as e:
                logger.warning(f"APIç›‘æ§å¤±è´¥ {endpoint}: {e}")
                response_times.append(0)

        avg_response_time = sum(response_times) / len(response_times) if response_times else 0

        return {
            'avg_response_time': avg_response_time,
            'max_response_time': max(response_times) if response_times else 0
        }

    def collect_monitoring_data(self) -> Dict[str, Any]:
        """æ”¶é›†æ‰€æœ‰ç›‘æ§æ•°æ®"""
        timestamp = datetime.now().isoformat()

        system_metrics = self.monitor_system_resources()
        db_metrics = self.monitor_database_performance()
        redis_metrics = self.monitor_redis_performance()
        api_metrics = self.monitor_api_performance()

        return {
            'timestamp': timestamp,
            'system': system_metrics,
            'database': db_metrics,
            'redis': redis_metrics,
            'api': api_metrics
        }

    def save_monitoring_data(self, data: Dict[str, Any]):
        """ä¿å­˜ç›‘æ§æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            filename = f"attendance-monitoring-data-{datetime.now().strftime('%Y%m%d')}.json"
            with open(filename, 'a', encoding='utf-8') as f:
                f.write(json.dumps(data, ensure_ascii=False) + '\n')
            logger.info(f"ç›‘æ§æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç›‘æ§æ•°æ®å¤±è´¥: {e}")

    def generate_performance_report(self, data_list: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not data_list:
            return "æ— ç›‘æ§æ•°æ®"

        # è®¡ç®—å¹³å‡å€¼
        avg_cpu = sum([d['system']['cpu_percent'] for d in data_list]) / len(data_list)
        avg_memory = sum([d['system']['memory_percent'] for d in data_list]) / len(data_list)
        avg_db_time = sum([d['database']['query_time'] for d in data_list]) / len(data_list)
        avg_redis_hit = sum([d['redis']['hit_rate'] for d in data_list]) / len(data_list)
        avg_api_time = sum([d['api']['avg_response_time'] for d in data_list]) / len(data_list)

        report = f"""
# è€ƒå‹¤æ¨¡å—æ€§èƒ½ç›‘æ§æŠ¥å‘Š

**æŠ¥å‘Šæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç›‘æ§æ—¶é•¿**: {len(data_list)} ä¸ªæ•°æ®ç‚¹

## ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
- **å¹³å‡CPUä½¿ç”¨ç‡**: {avg_cpu:.2f}%
- **å¹³å‡å†…å­˜ä½¿ç”¨ç‡**: {avg_memory:.2f}%
- **æ•°æ®åº“æŸ¥è¯¢å¹³å‡è€—æ—¶**: {avg_db_time:.2f}ms
- **Redisç¼“å­˜å‘½ä¸­ç‡**: {avg_redis_hit:.2f}%
- **APIå¹³å‡å“åº”æ—¶é—´**: {avg_api_time:.2f}ms

## æ€§èƒ½å»ºè®®
"""

        # æ ¹æ®ç›‘æ§æ•°æ®ç”Ÿæˆå»ºè®®
        if avg_cpu > 80:
            report += "- âš ï¸ CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½\n"
        if avg_memory > 80:
            report += "- âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼\n"
        if avg_db_time > 100:
            report += "- âš ï¸ æ•°æ®åº“æŸ¥è¯¢è¾ƒæ…¢ï¼Œå»ºè®®ä¼˜åŒ–SQLè¯­å¥\n"
        if avg_redis_hit < 80:
            report += "- âš ï¸ Redisç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥\n"
        if avg_api_time > 500:
            report += "- âš ï¸ APIå“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–æ¥å£æ€§èƒ½\n"

        if all([avg_cpu < 80, avg_memory < 80, avg_db_time < 100, avg_redis_hit > 80, avg_api_time < 500]):
            report += "- âœ… ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œå„é¡¹æŒ‡æ ‡æ­£å¸¸\n"

        report += f"""
---
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç›‘æ§è„šæœ¬ç‰ˆæœ¬**: v1.0.0
"""

        return report

    def start_monitoring(self, interval: int = 60, duration: int = 3600):
        """
        å¼€å§‹ç›‘æ§

        Args:
            interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
            duration: ç›‘æ§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        """
        logger.info(f"å¼€å§‹æ€§èƒ½ç›‘æ§ï¼Œé—´éš” {interval} ç§’ï¼ŒæŒç»­ {duration} ç§’")

        data_list = []
        start_time = time.time()

        try:
            while time.time() - start_time < duration:
                # æ”¶é›†ç›‘æ§æ•°æ®
                data = self.collect_monitoring_data()
                data_list.append(data)

                # ä¿å­˜æ•°æ®
                self.save_monitoring_data(data)

                # æ‰“å°å½“å‰çŠ¶æ€
                logger.info(f"CPU: {data['system']['cpu_percent']:.1f}%, "
                           f"å†…å­˜: {data['system']['memory_percent']:.1f}%, "
                           f"DBæŸ¥è¯¢: {data['database']['query_time']:.2f}ms, "
                           f"Rediså‘½ä¸­ç‡: {data['redis']['hit_rate']:.1f}%, "
                           f"APIå“åº”: {data['api']['avg_response_time']:.2f}ms")

                # ç­‰å¾…ä¸‹ä¸€ä¸ªç›‘æ§å‘¨æœŸ
                time.sleep(interval)

        except KeyboardInterrupt:
            logger.info("ç›‘æ§è¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            logger.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            if data_list:
                report = self.generate_performance_report(data_list)
                report_file = f"attendance-performance-report-{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(report)
                logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

    def check_performance_bottlenecks(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = {
            'database': [],
            'redis': [],
            'system': [],
            'api': []
        }

        try:
            # æ£€æŸ¥æ…¢æŸ¥è¯¢
            if self.db_connection:
                cursor = self.db_connection.cursor()
                cursor.execute("SHOW VARIABLES LIKE 'slow_query_log'")
                slow_log_enabled = cursor.fetchone()
                if slow_log_enabled and slow_log_enabled[1] == 'OFF':
                    bottlenecks['database'].append("æ…¢æŸ¥è¯¢æ—¥å¿—æœªå¯ç”¨")

                cursor.execute("SHOW VARIABLES LIKE 'long_query_time'")
                long_query_time = cursor.fetchone()
                if long_query_time and float(long_query_time[1]) > 2:
                    bottlenecks['database'].append(f"æ…¢æŸ¥è¯¢é˜ˆå€¼è®¾ç½®è¾ƒé«˜: {long_query_time[1]}ç§’")

                cursor.close()

            # æ£€æŸ¥Redisé…ç½®
            if self.redis_client:
                info = self.redis_client.info()
                maxmemory = info.get('maxmemory', 0)
                if maxmemory == 0:
                    bottlenecks['redis'].append("Redisæœªè®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶")

            # æ£€æŸ¥ç³»ç»Ÿé…ç½®
            cpu_count = psutil.cpu_count()
            if cpu_count < 4:
                bottlenecks['system'].append(f"CPUæ ¸å¿ƒæ•°è¾ƒå°‘: {cpu_count}æ ¸")

            memory = psutil.virtual_memory()
            if memory.total < 4 * 1024 * 1024 * 1024:  # 4GB
                bottlenecks['system'].append(f"å†…å­˜è¾ƒå°: {memory.total / (1024**3):.1f}GB")

        except Exception as e:
            logger.error(f"æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆæ—¶å‘ç”Ÿé”™è¯¯: {e}")

        return bottlenecks

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è€ƒå‹¤æ¨¡å—æ€§èƒ½ç›‘æ§å·¥å…·")
    print("=" * 50)

    # é…ç½®æ•°æ®åº“å’ŒRedisè¿æ¥ä¿¡æ¯
    db_config = {
        'host': 'localhost',
        'port': 33060,
        'user': 'root',
        'password': '',
        'database': 'smart_admin_v3'
    }

    redis_config = {
        'host': 'localhost',
        'port': 6389,
        'db': 1,
        'password': 'zkteco3100'
    }

    # åˆ›å»ºç›‘æ§å™¨å®ä¾‹
    monitor = AttendancePerformanceMonitor(db_config, redis_config)

    # æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆ
    print("\nğŸ” æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆ...")
    bottlenecks = monitor.check_performance_bottlenecks()

    has_bottlenecks = False
    for category, issues in bottlenecks.items():
        if issues:
            has_bottlenecks = True
            print(f"\n{category.upper()} ç“¶é¢ˆ:")
            for issue in issues:
                print(f"  âš ï¸  {issue}")

    if not has_bottlenecks:
        print("âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½ç“¶é¢ˆ")

    # å¼€å§‹ç›‘æ§
    print("\nğŸ“Š å¼€å§‹æ€§èƒ½ç›‘æ§...")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")

    try:
        # ç›‘æ§10åˆ†é’Ÿï¼Œæ¯30ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
        monitor.start_monitoring(interval=30, duration=600)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç›‘æ§å·²åœæ­¢")

    print("\nğŸ‰ æ€§èƒ½ç›‘æ§å®Œæˆï¼")

if __name__ == "__main__":
    main()