# 15-消费流水数据准确性与性能设计

## 📋 模块概述

**设计目标**：在保证数据绝对准确的前提下，实现海量数据的高性能查询。

**核心原则**：
- 🔴 数据准确性 > 性能 > 便利性
- 🔴 原始流水数据绝对不能错
- 🔴 统计数据可以重算，但流水不能丢
- 🔴 **交易表必须包含所有业务关键字段**

**设计收益**：
- ✅ 流水数据100%准确
- ✅ 查询性能提升50-500倍
- ✅ 存储成本降低70%
- ✅ 自动化对账和修复
- ✅ **支持多维度业务分析**

---

## 🔑 交易表字段完整性检查

### 必需字段清单（新增）

**交易表(`POSID_TRANSACTION`)必须包含以下业务字段**：

| 字段类别 | 字段名 | 数据类型 | 说明 | 用途 |
|---------|--------|---------|------|------|
| **区域信息** | `area_manage_mode` | INT | 经营模式（消费时快照） | 统计分析、模式对比 |
| | `area_sub_type` | VARCHAR(50) | 区域细分类型（消费时快照） | 场所类型分析 |
| **金额来源** | `amount_source` | VARCHAR(50) | 定值来源标记 | 评估配置优先级 |
| | | | account_kind/area_default/system | 账户定值/区域定值/系统默认 |
| **餐别信息** | `meal_category_id` | VARCHAR(32) | 大餐别ID（如有） | 餐别分类统计 |
| | `meal_id` | VARCHAR(32) | 具体餐别ID（如有） | 详细餐别统计 |
| **考勤标识** | `is_attendance_consume` | BOOLEAN | 是否考勤消费 | 考勤消费统计 |

**重要说明**：
1. **快照原则**：`area_manage_mode`和`area_sub_type`记录消费时刻的区域状态，即使后续区域配置变更，历史数据也不受影响
2. **可空原则**：超市制消费时`meal_category_id`和`meal_id`可为NULL
3. **来源追踪**：`amount_source`用于分析定值配置的实际使用情况，优化配置策略

---

## 🏗️ 整体架构设计
## 📋 IOE-DREAM七微服务架构

**核心架构组成**:
- **Gateway Service (8080)**: API网关
- **Common Service (8088)**: 公共模块微服务
- **DeviceComm Service (8087)**: 设备通讯微服务
- **OA Service (8089)**: OA微服务
- **Access Service (8090)**: 门禁服务
- **Attendance Service (8091)**: 考勤服务
- **Video Service (8092)**: 视频服务
- **Consume Service (8094)**: 消费服务
- **Visitor Service (8095)**: 访客服务

**架构特点**:
- 基于Spring Boot 3.5.8 + Java 17
- 严格遵循企业级微服务规范
- 支持高并发、高可用、水平扩展

**技术栈标准**:
- **数据库**: MySQL 8.0 + Druid连接池
- **缓存**: Redis + Caffeine多级缓存
- **注册中心**: Nacos
- **配置中心**: Nacos Config
- **认证授权**: Sa-Token

## 🏗️ 四层架构规范

**标准架构模式**:
```
Controller (接口控制层)
    ↓
Service (核心业务层)
    ↓
Manager (流程管理层)
    ↓
DAO (数据访问层)
```

**层级职责**:
- **Controller层**: HTTP请求处理、参数验证、权限控制
- **Service层**: 核心业务逻辑、事务管理、业务规则验证
- **Manager层**: 复杂流程编排、多数据组装、第三方服务集成
- **DAO层**: 数据库CRUD操作、SQL查询实现、数据访问边界

**严格禁止跨层访问**: Controller不能直接调用Manager/DAO！
### 1.1 数据分层架构
## ⚠️ IOE-DREAM零容忍规则（强制执行）

**必须遵守的架构规则**:
- ✅ **必须使用 @Resource 注入依赖**
- ✅ **必须使用 @Mapper 注解** (禁止@Repository)
- ✅ **必须使用 Dao 后缀** (禁止Repository)
- ✅ **必须使用 @RestController 注解**
- ✅ **必须使用 @Valid 参数校验**
- ✅ **必须返回统一ResponseDTO格式**
- ✅ **必须遵循四层架构边界**

**严格禁止事项**:
- ❌ **禁止使用 @Autowired 注入**
- ❌ **禁止使用 @Repository 注解**
- ❌ **禁止使用 Repository 后缀命名**
- ❌ **禁止跨层访问**
- ❌ **禁止在Controller中包含业务逻辑**
- ❌ **禁止直接访问数据库**

**违规后果**: P0级问题，立即修复，禁止合并！

```mermaid
flowchart TB
    subgraph 写入层-保证准确性
        A[消费请求] --> B[业务验证]
        B --> C[扣款事务]
        C --> D[写入流水]
        D --> E[MQ异步通知]
    end
    
    subgraph 存储层-分层存储
        F1[热数据-3个月\nMySQL主库]
        F2[温数据-1年\nMySQL归档库]
        F3[冷数据-永久\nOSS对象存储]
    end
    
    subgraph 统计层-分层汇总
        G1[实时统计-Redis\n今日数据]
        G2[小时统计表\nT+1小时]
        G3[日统计表\nT+1天]
        G4[月统计表\nT+1月]
    end
    
    subgraph 查询层-智能路由
        H1[今日实时查询]
        H2[历史报表查询]
        H3[明细流水查询]
        H4[冷数据归档查询]
    end
    
    subgraph 校验层-保证准确
        I1[写入时实时校验]
        I2[每日定时对账]
        I3[每月财务对账]
    end
    
    D --> F1
    E --> G1
    F1 -.3个月后.-> F2
    F2 -.1年后.-> F3
    
    F1 --> G2
    G2 --> G3
    G3 --> G4
    
    G1 --> H1
    G3 --> H2
    F1 --> H3
    F2 --> H4
    
    D --> I1
    G3 --> I2
    F1 --> I3
```

---

## 1️⃣ 数据准确性保证机制

### 1.1 消费流水表核心字段设计

**主键和流水号：**
- `id`：主键，UUID
- `transaction_no`：流水号，全局唯一，格式：`设备编号+日期+序号+随机数`
- `partition_key`：分区键，格式：`2025-01`，用于按月分区

**业务字段：**
- `account_id`：账户ID
- `consume_money`：消费金额（单位：分）
- `final_money`：实付金额（单位：分）

**余额快照（关键设计）：**
- `balance_before`：消费前余额（分）
- `balance_after`：消费后余额（分）
- `subsidy_used`：补贴使用明细（JSON格式）

**数据校验字段：**
- `data_checksum`：数据校验和（MD5），基于流水号+账户ID+金额+余额前后计算
- `is_verified`：是否已对账（Boolean）

**审计字段：**
- `create_time`：创建时间（精确到毫秒）
- `create_source`：数据来源（ONLINE-在线/OFFLINE-离线上传）
- `device_id`：设备ID
- `status`：状态（SUCCESS-成功/FAILED-失败/REFUND-已退款）

### 1.2 写入流程（保证准确性）

**步骤：**
1. **获取分布式锁**：账户级别锁，锁定账户，超时时间5秒
2. **查询当前余额**：使用`SELECT FOR UPDATE`行锁，获取准确余额
3. **计算消费金额**：根据定值规则、商品价格、补贴等计算
4. **验证余额充足**：余额前 >= 消费金额
5. **扣除余额**：余额后 = 余额前 - 消费金额
6. **更新账户余额**：使用乐观锁（版本号），防止并发冲突
7. **生成流水号**：分布式唯一流水号，使用Redis自增序列或雪花算法
8. **计算校验和**：MD5(流水号+账户ID+金额+余额前+余额后)
9. **写入流水表**：一次性写入，不允许更新
10. **释放锁，提交事务**
11. **事务后发送MQ**：通知统计服务更新实时数据

**关键设计点：**
- 使用分布式锁保证并发安全
- 余额前后快照，用于流水连续性验证
- 数据校验和，防止数据被篡改
- 事务后发送MQ，保证流水写入成功后才通知

### 1.3 数据完整性验证

#### 实时验证（写入时）

**验证内容：**
1. **流水号唯一性**：检查流水号是否重复
2. **余额连续性**：验证`余额后 = 余额前 - 消费金额`
3. **数据完整性**：重新计算校验和，与保存的校验和比对
4. **金额合理性**：消费金额 > 0，余额前 >= 0，余额后 >= 0

**验证失败处理：**
- 拒绝写入
- 记录错误日志
- 发送告警

#### 定时验证（每日凌晨3点）

**验证维度：**

**1. 账户流水链验证**
- 按账户维度查询昨日所有流水，按时间排序
- 验证流水连续性：第N条的`余额后` = 第N+1条的`余额前`
- 验证余额计算：每条流水的`余额后 = 余额前 - 消费金额`

**2. 金额汇总验证**
- 从原始流水表统计昨日总金额、总笔数、总人数
- 从日统计表读取昨日统计数据
- 对比两者是否一致
- 不一致则告警，并自动修复统计表

**3. 数据校验和验证**
- 随机抽取1000条流水
- 重新计算校验和
- 与保存的校验和比对
- 发现不一致立即告警

**验证结果处理：**
- 验证通过：标记`is_verified = TRUE`
- 验证失败：发送告警，生成差异报告
- 自动修复：更新统计表数据
- 记录验证日志：验证时间、验证结果、差异详情

---

## 2️⃣ 海量数据存储策略

### 2.1 数据分层存储

#### 热数据层（3个月）

**存储位置：** MySQL主库

**特点：**
- 数据量：3个月约1500万条
- 存储介质：SSD高速磁盘
- 查询频率：高频查询
- 按月分区：每月一个分区，自动创建

**分区策略：**
- 分区字段：`partition_key`（格式：2025-01）
- 分区方式：RANGE分区
- 自动管理：每月自动创建下月分区

**索引设计：**
- 主键索引：`id`
- 唯一索引：`transaction_no`
- 组合索引：`(partition_key, account_id, create_time)`
- 组合索引：`(partition_key, create_time, status)`
- 覆盖索引：`(partition_key, create_time, account_id, final_money, status)`

**查询优化：**
- 查询必带`partition_key`，实现分区剪裁
- 利用覆盖索引，避免回表
- 单分区数据量500万条，查询响应30ms

#### 温数据层（1年）

**存储位置：** MySQL归档库（只读）

**特点：**
- 数据量：1年约1.2亿条
- 存储介质：HDD机械磁盘
- 查询频率：中低频查询
- 成本：中等

**迁移策略：**
- 迁移时机：每月1号凌晨4点
- 迁移对象：3个月前的分区
- 迁移方式：批量读取+批量写入，每批1万条
- 验证机制：迁移前后数据量比对
- 删除方式：使用`DROP PARTITION`，秒级完成

#### 冷数据层（永久）

**存储位置：** OSS对象存储

**特点：**
- 数据量：无限
- 存储格式：Parquet列式存储（压缩比高）
- 查询频率：极低频
- 成本：极低

**归档策略：**
- 归档时机：每月1号凌晨5点
- 归档对象：1年前的数据
- 归档方式：导出为Parquet格式，上传OSS
- 访问方式：通过大数据平台查询（Hive/Presto）

### 2.2 数据生命周期

```
写入 → 热数据(3个月) → 温数据(1年) → 冷数据(永久)
      [主库-SSD]      [归档库-HDD]   [OSS-对象存储]
      高频查询30ms     中频查询200ms   低频查询5s
```

**数据迁移自动化：**
- 定时任务自动执行
- 迁移前验证数据完整性
- 迁移后再次验证
- 失败自动重试3次
- 发送迁移报告

---

## 3️⃣ 统计数据生成机制

### 3.1 实时统计层（Redis）

**用途：** 今日数据实时统计，秒级刷新

**统计维度：**
- 今日消费总金额：String类型，INCR累加
- 今日消费总笔数：String类型，INCR累加
- 今日消费人数：Set类型，SADD去重
- 各区域统计：Hash类型，HINCRBY累加
- 各餐别统计：Hash类型，HINCRBY累加
- 各时段统计：Hash类型，HINCRBY累加

**更新机制：**
- 消费成功后异步更新Redis
- 使用MQ解耦，保证事务后更新
- 失败重试3次
- 每天23:59:59过期

**优点：**
- 响应时间：5ms
- 实时大屏直接读取
- 内存存储，性能极高

### 3.2 小时统计表（准实时）

**用途：** 每小时汇总，用于当天详细分析

**统计内容：**
- 基础指标：总笔数、总金额、消费人数、平均金额
- 维度统计：区域统计、餐别统计、卡类统计（JSON存储）

**生成时机：**
- 每小时第1分钟执行
- 统计上一小时数据
- 从原始流水表聚合计算

**表设计要点：**
- 唯一键：`(stat_date, stat_hour)`
- 支持幂等：重复执行覆盖
- JSON字段存储维度明细

### 3.3 日统计表（T+1）

**用途：** 每日汇总，日报、月报基础

**统计结构：**

**主表（POSID_STAT_DAILY）：**
- 总体指标：总笔数、总金额、消费人数、考勤人数
- 同环比：同比增长率、环比增长率
- 数据追溯：来源分区、源记录数
- 数据校验：校验和、是否已验证

**维度明细表：**
- 区域维度表（POSID_STAT_DAILY_AREA）
- 餐别维度表（POSID_STAT_DAILY_MEAL）
- 卡类维度表（POSID_STAT_DAILY_KIND）

**生成时机：**
- 每天凌晨1点执行
- 统计昨日数据
- 从原始流水表聚合计算

**幂等性保证：**
- 执行前检查是否已存在
- 已存在则跳过
- 支持手动重跑（删除后重新生成）

**数据校验：**
- 生成后立即验证
- 与原始表比对金额、笔数、人数
- 不一致自动修复
- 标记验证状态

### 3.4 月统计表（历史分析）

**用途：** 月度汇总，长期趋势分析

**统计内容：**
- 月度总体：总笔数、总金额、消费人数
- 月度特有：日均消费、单日最高、最高日期
- 维度明细：各区域、各餐别月度统计

**生成时机：**
- 每月1号凌晨2点执行
- 汇总上月数据
- 从日统计表汇总（不是从原始表）

---

## 4️⃣ 查询性能优化

### 4.1 智能查询路由策略

**路由规则：**

| 查询场景 | 查询日期 | 数据源 | 响应时间 |
|---------|---------|--------|---------|
| 实时统计 | 今日 | Redis | 5ms |
| 历史报表 | 昨日-3个月 | 日统计表 | 10ms |
| 流水明细 | 3个月内 | 热数据库（分区） | 30ms |
| 流水明细 | 3个月-1年 | 归档库 | 200ms |
| 流水明细 | 1年前 | OSS冷数据 | 5s |
| 月度报表 | 任意月份 | 月统计表 | 50ms |

**路由逻辑：**
1. 判断查询日期是否今日 → Redis实时统计
2. 判断查询类型是汇总还是明细 → 统计表 vs 原始表
3. 判断日期范围 → 热数据 vs 归档 vs 冷数据
4. 判断查询频率 → 是否启用缓存

### 4.2 分区查询优化

**分区剪裁原理：**
- 查询必须带`partition_key`字段
- MySQL自动识别需要扫描的分区
- 只扫描相关分区，性能提升10倍

**优化前（全表扫描）：**
```
查询条件：account_id = 'A123456' AND create_time >= '2025-01-01'
扫描分区：全部12个分区
响应时间：500ms
```

**优化后（分区剪裁）：**
```
查询条件：partition_key IN ('2025-01', '2025-02', '2025-03') 
         AND account_id = 'A123456' 
         AND create_time >= '2025-01-01'
扫描分区：仅3个分区
响应时间：30ms
性能提升：16倍
```

### 4.3 索引优化策略

**覆盖索引：**
- 创建包含所有查询字段的索引
- 避免回表查询
- 适用于统计类查询

**示例：**
```
索引：(partition_key, create_time, account_id, final_money, status)
查询：SELECT account_id, SUM(final_money), COUNT(*)
     WHERE partition_key = '2025-01' 
     GROUP BY account_id
优化效果：完全走索引，无需回表，性能提升5倍
```

### 4.4 查询缓存策略

**缓存规则：**
- 今日数据：不缓存（实时变化）
- 昨日及历史：缓存10分钟
- 高频查询：缓存1小时
- 缓存Key：查询条件MD5

**缓存失效：**
- 定时过期（10分钟-1小时）
- 数据修正后主动删除
- 新月份统计生成后主动刷新

---

## 5️⃣ 性能基准数据

### 5.1 写入性能

| 场景 | TPS | 平均响应 | P99响应 |
|------|-----|---------|--------|
| 正常消费 | 2000+ | 50ms | 150ms |
| 高峰期 | 5000+ | 80ms | 200ms |
| 离线上传 | 10000+ | 20ms | 50ms |

### 5.2 查询性能对比

| 查询类型 | 原方案 | 重构后 | 提升倍数 |
|---------|-------|--------|---------|
| 今日实时统计 | 200ms | 5ms | 40倍 |
| 昨日日报 | 500ms | 10ms | 50倍 |
| 月度报表 | 5000ms | 50ms | 100倍 |
| 明细查询（热数据） | 300ms | 30ms | 10倍 |
| 明细查询（归档） | 2000ms | 200ms | 10倍 |

### 5.3 存储成本

| 数据层 | 数据量（1年） | 存储成本 | 占比 |
|-------|-------------|---------|------|
| 热数据（3个月） | 1500万条 | 高 | 15% |
| 温数据（1年） | 1.2亿条 | 中 | 12% |
| 冷数据（永久） | 按年累积 | 低 | 3% |
| 统计表 | 365条/年 | 极低 | 0.1% |
| **总成本** | - | - | **降低70%** |

---

## 6️⃣ 监控告警机制

### 6.1 实时监控指标

**写入监控：**
- TPS（每秒交易数）：正常2000+，告警阈值<100
- 写入成功率：正常>99.9%，告警阈值<99%
- 平均响应时间：正常50ms，告警阈值>200ms
- 数据库连接池：正常<50%，告警阈值>80%

**查询监控：**
- 查询QPS：正常1000+，告警阈值<100
- 平均响应时间：正常30ms，告警阈值>200ms
- 慢查询数量：告警阈值>10个/分钟
- 缓存命中率：正常>80%，告警阈值<60%

**数据准确性监控：**
- 数据校验失败率：告警阈值>0.01%
- 余额连续性错误：告警阈值>0
- 统计表差异数：告警阈值>5条/天
- 流水链断裂数：告警阈值>0

### 6.2 定时校验报告

**每日校验报告（凌晨3点）：**
- 昨日流水总数、总金额
- 流水连续性验证结果
- 统计表一致性验证结果
- 发现的问题和自动修复记录

**每月对账报告（每月2号）：**
- 上月流水汇总
- 与财务系统对账结果
- 冷热数据迁移报告
- 存储空间使用情况

### 6.3 告警通知

**告警级别：**
- P0-紧急：数据准确性问题（立即处理）
- P1-重要：性能严重下降（30分钟内处理）
- P2-一般：性能轻微下降（1小时内处理）
- P3-提醒：资源使用告警（当天处理）

**通知方式：**
- P0：电话+短信+邮件+企业微信
- P1：短信+邮件+企业微信
- P2：邮件+企业微信
- P3：邮件

---

## 7️⃣ 运维管理

### 7.1 自动化任务

**每小时任务：**
- 生成上一小时统计（01分执行）
- 检查分区大小（30分执行）

**每日任务：**
- 生成昨日统计（凌晨1点）
- 验证昨日数据（凌晨3点）
- 发送日报（早上8点）

**每月任务：**
- 生成上月统计（1号凌晨2点）
- 迁移热数据到温数据（1号凌晨4点）
- 归档温数据到冷数据（1号凌晨5点）
- 创建下月分区（1号凌晨6点）
- 发送月报（2号早上9点）

### 7.2 数据修复

**自动修复：**
- 统计表数据不一致：自动重新计算并更新
- 缓存数据过期：自动刷新
- 流水链断裂（小额）：自动生成补单流水

**人工修复：**
- 流水链断裂（大额）：生成工单，人工处理
- 数据校验和不匹配：人工核查原因
- 余额异常：锁定账户，人工核查

### 7.3 故障恢复

**数据库故障：**
- 主库故障：自动切换到从库（秒级）
- 归档库故障：降级到只读热数据

**Redis故障：**
- 实时统计故障：降级到数据库查询
- 缓存故障：直接查询数据库

**统计任务失败：**
- 自动重试3次
- 失败后发送告警
- 支持手动重跑

---

## 🎯 总结

### 核心设计理念

**数据准确性保证：**
1. 余额前后快照 → 流水连续性验证
2. 数据校验和 → 防篡改
3. 定时对账 → 自动发现问题
4. 自动修复 → 保证最终一致性

**海量数据性能：**
1. 分层存储 → 热温冷三层，成本降低70%
2. 按月分区 → 查询性能提升10倍
3. 统计表加速 → 报表查询提升100倍
4. 智能路由 → 自动选最优数据源

**架构优势：**
1. **准确**：多重校验，自动对账
2. **快速**：分层存储，智能路由
3. **可靠**：自动修复，告警完善
4. **省钱**：自动归档，成本可控

### 关键指标

| 指标 | 目标值 | 说明 |
|------|-------|------|
| 数据准确率 | 100% | 绝对不允许错 |
| 写入TPS | 2000+ | 满足高峰需求 |
| 查询响应 | 30ms | 热数据查询 |
| 报表响应 | 10ms | 统计表查询 |
| 存储成本 | -70% | 相比全量存储 |
| 数据保留 | 永久 | 冷数据归档 |

---

## 📝 更新说明

### v2.0 (2025-10-31)
- ✅ 新增"交易表字段完整性检查"章节
- ✅ 补充7个业务关键字段（经营模式、区域类型、定值来源、餐别信息、考勤标识）
- ✅ 明确字段快照原则和可空原则

---

**文档版本**：v2.0  
**创建时间**：2025-10-31  
**适用版本**：POSID v3.13.1+

